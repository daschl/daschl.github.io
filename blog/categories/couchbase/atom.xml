<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">

  <title><![CDATA[Category: Couchbase | Nitschinger.at]]></title>
  <link href="http://daschl.github.io/blog/categories/couchbase/atom.xml" rel="self"/>
  <link href="http://daschl.github.io/"/>
  <updated>2013-12-19T10:31:42+01:00</updated>
  <id>http://daschl.github.io/</id>
  <author>
    <name><![CDATA[Michael Nitschinger]]></name>
    
  </author>
  <generator uri="http://octopress.org/">Octopress</generator>

  
  <entry>
    <title type="html"><![CDATA[What's New in the Couchbase Java SDK 1.2]]></title>
    <link href="http://daschl.github.io/What-s-new-in-the-Couchbase-Java-SDK-1-2"/>
    <updated>2013-10-11T14:49:48+02:00</updated>
    <id>http://daschl.github.io/What-s-new-in-the-Couchbase-Java-SDK-1-2</id>
    <content type="html"><![CDATA[<p>For all users of our Java SDK, we prepared some nice additions for you. This post covers them in detail and shows how you can get more productive.</p>

<p>Note that this blog post assumes you are running the 1.2.1 release, because there have been some slight changes between 1.2.0 and 1.2.1 that affect for example the listener support and metrics collection.</p>

<h2>Maven Central Distribution</h2>

<p>From the 1.2.0 release forward, the Java SDK is distributed directly from Maven Central. This means that you don&rsquo;t need to include the Couchbase repository anymore. The following maven code is enough to get started (note that the groupId has changed):</p>

<p>``` xml
<dependencies></p>

<pre><code>&lt;dependency&gt;
    &lt;groupId&gt;com.couchbase.client&lt;/groupId&gt;
    &lt;artifactId&gt;couchbase-client&lt;/artifactId&gt;
    &lt;version&gt;1.2.1&lt;/version&gt;
&lt;/dependency&gt;
</code></pre>

<p></dependencies>
```</p>

<p>This will automatically load the latest spymemcached dependency in as well (for 1.2.0 it&rsquo;s 2.10.0). Before we dig into what has changed, <a href="http://docs.couchbase.com/couchbase-sdk-java-1.2/#release-notes-for-couchbase-client-library-java-120-ga-13-september-2013">here</a> are the release notes for a quick reference.</p>

<h2>Listener Support</h2>

<p>Until now, there were two ways to get the result of an asynchronous request. Either by blocking the current thread like so:</p>

<p>``` java
// do an async operation (returns immediately)
OperationFuture<Boolean> setFuture = client.set(&ldquo;key&rdquo;, &ldquo;value&rdquo;);</p>

<p>// block the current thread
Boolean result = setFuture.get();
```</p>

<p>Or to loop on the non-blocking future methods. This is especially helpful if you are dealing with a list of futures.</p>

<p>``` java
List&lt;OperationFuture<Boolean>> futures = new ArrayList&lt;OperationFuture<Boolean>>();
for (int i = 0; i &lt; 100; i++) {
  futures.add(client.set(&ldquo;key-&rdquo; + i, &ldquo;value&rdquo;));
}</p>

<p>while (!futures.isEmpty()) {
  Iterator&lt;OperationFuture<Boolean>> iter = futures.iterator();
  while (iter.hasNext()) {</p>

<pre><code>OperationFuture&lt;Boolean&gt; future = iter.next();
if (future.isDone()) {
  iter.remove();
}
</code></pre>

<p>  }
}
```</p>

<p>Now since 1.2.0, there is a new way to deal with responses &ndash; adding listeners. The idea is to supply a callback to the future which will be executed once the operation is done. A simple example is shown here:</p>

<p>``` java
OperationFuture<Boolean> setFuture = client.set(&ldquo;key&rdquo;, &ldquo;value&rdquo;);
setFuture.addListener(new OperationCompletionListener() {
  @Override
  public void onComplete(OperationFuture&lt;?> future) throws Exception {</p>

<pre><code>System.out.println(future.get());
</code></pre>

<p>  }
});
```</p>

<p>Note that the <code>.get()</code> method on the future will not block anymore because the result is already computed. Whatever you put in the callback method will be executed asynchronously on the thread pool. To see how flexible that approach is, let&rsquo;s rewrite the example from above waiting until the 100 futures are done.</p>

<p>``` java
final CountDownLatch latch = new CountDownLatch(100);
for (int i = 0; i &lt; 100; i++) {
  OperationFuture<Boolean> future = client.set(&ldquo;key-&rdquo; + i, &ldquo;value&rdquo;);
  future.addListener(new OperationCompletionListener() {</p>

<pre><code>@Override
public void onComplete(OperationFuture&lt;?&gt; future) throws Exception {
  latch.countDown();
}
</code></pre>

<p>  });
}
latch.await();
```</p>

<p>Here we are using a <a href="http://docs.oracle.com/javase/7/docs/api/java/util/concurrent/CountDownLatch.html">CountDownLatch</a> which waits on the current thread as long as it has been counted down a hundred times. Exactly what we need in our situation, but the code is much easier to read. More importantly, its much more flexible because other things like firing off a new request, querying a web service or calculating a result can be done.</p>

<p>It is also possible to override the default <code>ExecutorService</code> implementation with a custom one. This may be needed if the default behavior (Basically a upper-bounded cachedThreadPool) does not suite your needs. Also, you should use this approach if you create a bunch of <code>CouchbaseClient</code> instances so you can share the same service across all of them.</p>

<p>``` java
// Create the Builder
CouchbaseConnectionFactoryBuilder builder = new CouchbaseConnectionFactoryBuilder();</p>

<p>// Create a thread pool of 5 fixed threads
ExecutorService service = Executors.newFixedThreadPool(5);
// Set it in the builder
builder.setListenerExecutorService(service);</p>

<p>// Create the instance
CouchbaseClient client = new CouchbaseClient(builder.buildCouchbaseConnection(&hellip;));
```</p>

<h2>Enhanced Profiling Capabilities</h2>

<p>Getting insight into a running application is always difficult, so we set out to make it easier for you. We incorporated a library called <a href="http://metrics.codahale.com/">metrics</a> that profiles, depending on the configuration level chosen.</p>

<p>Before you can use it, you need to add this optional dependency:</p>

<p>``` xml
<dependency></p>

<pre><code>&lt;groupId&gt;com.codahale.metrics&lt;/groupId&gt;
&lt;artifactId&gt;metrics-core&lt;/artifactId&gt;
&lt;version&gt;3.0.1&lt;/version&gt;
</code></pre>

<p></dependency>
```</p>

<p>On the builder, there is a method that allows you to activate the the profiler:</p>

<p>``` java
CouchbaseConnectionFactoryBuilder builder = new CouchbaseConnectionFactoryBuilder();</p>

<p>// enable metric collection
builder.setEnableMetrics(MetricType.PERFORMANCE);
```</p>

<p>If you look at the <code>MetricType</code> enumeration you can see that there are three types of values you can choose from: OFF (which keeps metric collection off), PERFORMANCE (which only collects performance-relevant metrics) and DEBUG (which collects all kinds of metrics, including the performance ones). While the metrics library is quite efficient, keep in mind that metric collection takes some resources away from your application.</p>

<p>By default, the metric information will be printed out on the console every 30 seconds. You can run the following test code from your IDE and see how it looks:</p>

<p>``` java
CouchbaseConnectionFactoryBuilder builder = new CouchbaseConnectionFactoryBuilder();
builder.setEnableMetrics(MetricType.PERFORMANCE);</p>

<p>CouchbaseConnectionFactory cf =
  builder.buildCouchbaseConnection(Arrays.asList(new URI(&ldquo;<a href="http://127.0.0.1:8091/pools">http://127.0.0.1:8091/pools</a>&rdquo;)), &ldquo;default&rdquo;, &ldquo;&rdquo;);</p>

<p>CouchbaseClient client = new CouchbaseClient(cf);</p>

<p>while(true) {
  client.set(&ldquo;foo&rdquo;, &ldquo;bar&rdquo;);
  Thread.sleep(100);
}
```</p>

<p>Now wait 30 seconds and you&rsquo;ll see output like this in the console:</p>

<pre><code>10/8/13 12:04:14 PM ============================================================

-- Histograms ------------------------------------------------------------------
[MEM] Average Bytes read from OS per read
             count = 893
               min = 24
               max = 24
              mean = 24.00
            stddev = 0.00
            median = 24.00
              75% &lt;= 24.00
              95% &lt;= 24.00
              98% &lt;= 24.00
              99% &lt;= 24.00
            99.9% &lt;= 24.00
[MEM] Average Bytes written to OS per write
             count = 893
               min = 38
               max = 38
              mean = 38.00
            stddev = 0.00
            median = 38.00
              75% &lt;= 38.00
              95% &lt;= 38.00
              98% &lt;= 38.00
              99% &lt;= 38.00
            99.9% &lt;= 38.00
[MEM] Average Time on wire for operations (Âµs)
             count = 893
               min = 179
               max = 1730
              mean = 263.80
            stddev = 75.43
            median = 251.00
              75% &lt;= 280.00
              95% &lt;= 351.90
              98% &lt;= 425.36
              99% &lt;= 559.70
            99.9% &lt;= 1730.00

-- Meters ----------------------------------------------------------------------
[MEM] Request Rate: All
             count = 893
         mean rate = 9.92 events/second
     1-minute rate = 9.85 events/second
     5-minute rate = 9.68 events/second
    15-minute rate = 9.63 events/second
[MEM] Response Rate: All (Failure + Success + Retry)
             count = 893
         mean rate = 9.92 events/second
     1-minute rate = 9.85 events/second
     5-minute rate = 9.68 events/second
    15-minute rate = 9.63 events/second
</code></pre>

<p>I won&rsquo;t go into detail of all these metrics in this blog post, please refer to the documentation for a more complete picture. One more thing I want to show you is that the metrics library is also able to expose these metrics through JMX. All you need to do is set a system property that changes the output mode: <code>net.spy.metrics.reporter.type=jmx</code>. Other possible settings are <code>csv</code> and <code>slf4j</code>. If you choose a logger that prints out information at a given interval you can change it by setting <code>net.spy.metrics.reporter.interval</code> to anything else than 30.</p>

<p>So if you put the line <code>System.setProperty("net.spy.metrics.reporter.type", "jmx");</code> before the code shown above, you can open (for example) jConsole and switch to the MBeans tab of the application. You&rsquo;ll see a <code>metrics</code> subsection exposed that contains the same metrics as they would show up in the logs.</p>

<h2>CAS with Timeout</h2>

<p>Before 1.2.0, it was not possible in one command to do a <code>cas</code> update and set a new timeout at the same time. You had to do a second <code>touch</code> operation which was not efficient nor atomic. Now, the API exposes a new <code>cas()</code> method that allows you to pass in the timeout at the same time. It is easy to use:</p>

<p><code>java
client.cas("key", cas, nexExpiration, value);
</code></p>

<p>The asynchronous variations have been exposed since 1.2.1 as well.</p>

<h2>Initializing through Properties</h2>

<p>One thing that comes in handy if your cluster ip addresses change often is that you can now initialize a <code>CouchbaseClient</code> object based on system properties. Here is an example:</p>

<p>``` java
System.setProperty(&ldquo;cbclient.nodes&rdquo;, &ldquo;<a href="http://127.0.0.1:8091/pools">http://127.0.0.1:8091/pools</a>&rdquo;);
System.setProperty(&ldquo;cbclient.bucket&rdquo;, &ldquo;default&rdquo;);
System.setProperty(&ldquo;cbclient.password&rdquo;, &ldquo;&rdquo;);</p>

<p>CouchbaseConnectionFactoryBuilder builder = new CouchbaseConnectionFactoryBuilder();
CouchbaseConnectionFactory cf = builder.buildCouchbaseConnection();
CouchbaseClient client = new CouchbaseClient(cf);
```</p>

<p>Of course you can set these properties in your application container or during startup, so it&rsquo;s very flexible and not tied into your code directly. Note that if you forget to set one of these properties, the code will warn you like this:</p>

<pre><code>Exception in thread "main" java.lang.IllegalArgumentException: System property cbclient.nodes not set or empty
    at com.couchbase.client.CouchbaseConnectionFactory.&lt;init&gt;(CouchbaseConnectionFactory.java:160)
    at com.couchbase.client.CouchbaseConnectionFactoryBuilder$2.&lt;init&gt;(CouchbaseConnectionFactoryBuilder.java:318)
    at com.couchbase.client.CouchbaseConnectionFactoryBuilder.buildCouchbaseConnection(CouchbaseConnectionFactoryBuilder.java:318)
    at Main.main(Main.java:33)
    at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
    at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57)
    at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
    at java.lang.reflect.Method.invoke(Method.java:601)
    at com.intellij.rt.execution.application.AppMain.main(AppMain.java:120)
</code></pre>

<h2>Other Changes</h2>

<p>In addition to the enhancements shown above, the release includes &ndash; as always &ndash; numerous smaller bugfixes. The default poll interval for <code>ReplicateTo</code> and <code>PersistTo</code> has been lowered to <code>10ms</code> to account for performance changes that went into the Couchbase Sever 2.2 release. Also, the client now uses the <code>CRAM-MD5</code> authentication mechanism automatically if the server supports it (since 2.2 as well).</p>

<p>These awesome new features should be enough reason to upgrade right now! If anything pops up that doesn&rsquo;t work as expected, please ask customer support or open a ticket <a href="http://www.couchbase.com/issues/browse/JCBC">here</a>.</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Using the Reactor Processor for High-Performance TCP]]></title>
    <link href="http://daschl.github.io/Using-the-Reactor-Processor-for-High-Performance-TCP"/>
    <updated>2013-08-13T14:49:48+02:00</updated>
    <id>http://daschl.github.io/Using-the-Reactor-Processor-for-High-Performance-TCP</id>
    <content type="html"><![CDATA[<p>First, a disclaimer: the all-new <a href="https://github.com/reactor/reactor">Reactor</a> framework is still under heavy development, but it already provides a very promising basement for applications and libraries that need high throughput and low latency. We at <a href="http://www.couchbase.com/">Couchbase</a> aim to provide the highest throughput at the lowest latency, so it is very critical to build upon an infrastructure that can provide it. Current, we are performing early investigations for a possible &ldquo;next generation Java SDK&rdquo; and Reactor seems very promising so far.</p>

<p>This blog post shows you how to quickly set up a Processor (we&rsquo;ll see in a minute what that is) that dispatches requests to Consumers (also a very common term in Reactor). In our case, the Consumer is actually a TCP socket. Please note that the actual numbers, while impressive, can&rsquo;t be used for real world measurements. What you&rsquo;ll see here is a raw throughput test to define a baseline what can be expected under ideal conditions. We are also using localhost here to avoid network latency (which is the bottleneck for most network applications).</p>

<p>I&rsquo;m going to use a Couchbase server as an endpoint, but feel free to use whatever you want instead. The whole API is very generic and the consumers can be exchanged easily.</p>

<h2>Setup</h2>

<p>Before we can get started, all we need to do is include the <code>reactor-tcp</code> artifact from maven. Now you can do this through gradle, maven, ivy or what you want, but at this point, I would recommend you to check out the <a href="https://github.com/reactor/reactor">reactor</a> project directly from github and build it on your own, so you&rsquo;ll have the latest and greatest code in your local repository:</p>

<pre><code>$ git clone https://github.com/reactor/reactor.git
$ cd reactor
$ ./gradlew install
</code></pre>

<p>This will download and install everything you need. The next step is to create a maven or gradle project in your IDE, but I&rsquo;ll leave that part up to the reader. The maven dependency you need to include is:</p>

<p>``` xml
<dependency></p>

<pre><code>&lt;groupId&gt;org.projectreactor&lt;/groupId&gt;
&lt;artifactId&gt;reactor-tcp&lt;/artifactId&gt;
&lt;version&gt;1.0.0.BUILD-SNAPSHOT&lt;/version&gt;
</code></pre>

<p></dependency>
```</p>

<p>Or, for all gradle folks:</p>

<p>``` groovy
dependencies {</p>

<pre><code>compile 'org.projectreactor:reactor-tcp:1.0.0.BUILD-SNAPSHOT'
</code></pre>

<p>}
```</p>

<h2>The Processor</h2>

<p>Now, let&rsquo;s get to some actual code. The Processor is a very lightweight abstraction over the <a href="https://github.com/LMAX-Exchange/disruptor">LMAX Disruptor</a> a high performant RingBuffer. A RingBuffer provides much better characteristics than a normal Queue, and the Disruptor is heavily optimized for dispatching tasks in the nanosecond area (which means millions of operations per second). I recommend you to read <a href="https://github.com/LMAX-Exchange/disruptor/blob/master/docs/Disruptor.docx">this paper</a> and also check out talks by <a href="http://mechanical-sympathy.blogspot.co.at/">Martin Thompson</a> if you are interested.</p>

<p>The basic idea is that we decouple consumers from producers, so that each of them can work on their own pace (not blocking each other) and also benefiting from batching if the producers are faster than the consumers. We&rsquo;ll see why this is particularly important with TCP in a second.</p>

<p>A <code>Processor</code> can be created by instantiating a <code>ProcessorSpec</code> and defining some mandatory options. Then, the <code>Processor</code> is built for us.</p>

<p>``` java
ProcessorSpec&lt;Event<Buffer>> writeProcessor = new ProcessorSpec&lt;Event<Buffer>>()</p>

<pre><code>.dataSupplier(new Supplier&lt;Event&lt;Buffer&gt;&gt;() {
    @Override
    public Event&lt;Buffer&gt; get() {
      return new Event&lt;Buffer&gt;(new Buffer());
    }
})
.consume(new Node("127.0.0.1", environment))
.get();
</code></pre>

<p>```</p>

<p>Note that this <code>Spec</code> pattern is very common in reactor, as it allows for very easy and yet flexible object creation. There are a few things that we need to cover.</p>

<p>First, the generic type here is <code>Event&lt;Buffer&gt;</code>. The producers will wrap the payload (here we use raw <code>Buffers</code>) in an <code>Event</code> and the consumers will unwrap and use it properly. The <code>Event</code> type also allows for headers that can be used for custom routing, but we won&rsquo;t cover that here.</p>

<p>Second, the <code>dataSupplier</code> is a speciality of the Disruptor RingBuffer. In order to minimize garbage collection and make effective use of memory layout, we need to pre-allocate our container objects. They will be reused throughout the application and will never be garbage collected.</p>

<p>Third, through the <code>consume</code> method we can tell the <code>Processor</code> who will be notified when new data is added to the RingBuffer. In our case, the <code>Node</code> represents the TCP client which we&rsquo;ll build in a second.</p>

<p>Now, how do we write to the Processor? Let&rsquo;s add a simple method that does it for us:</p>

<p>``` java
public void write(final Buffer data) {</p>

<pre><code>final Operation&lt;Event&lt;Buffer&gt;&gt; op = writeProcessor.get();
op.get().setData(data);
op.commit();
</code></pre>

<p>}
```</p>

<p>Here, we get a <code>Operation</code> out of the processor (that wraps our data) and override it with the data that we actually want to store this time. You can see that we are not allocating new objects in the RingBuffer, we just use the old one that has been provided for us. With the <code>commit</code> method we put it back into the RingBuffer. Actually, behind the scenes, it makes use of Sequences and Barriers inside the RingBuffer, but this is completely hidden from us.</p>

<p>Here is the full code for the lazy reader:</p>

<p>``` java
import reactor.core.Environment;
import reactor.core.processor.Operation;
import reactor.core.processor.Processor;
import reactor.core.processor.spec.ProcessorSpec;
import reactor.event.Event;
import reactor.function.Supplier;
import reactor.io.Buffer;</p>

<p>public class MessageDispatcher {</p>

<p>  private final Environment environment;</p>

<p>  private final Processor&lt;Event<Buffer>> writeProcessor;</p>

<p>  public MessageDispatcher() {</p>

<pre><code>this(new Environment());
</code></pre>

<p>  }</p>

<p>  MessageDispatcher(final Environment env) {</p>

<pre><code>environment = env;

writeProcessor = new ProcessorSpec&lt;Event&lt;Buffer&gt;&gt;()
  .dataSupplier(new Supplier&lt;Event&lt;Buffer&gt;&gt;() {
    @Override
    public Event&lt;Buffer&gt; get() {
      return new Event&lt;Buffer&gt;(new Buffer());
    }
  })
  .consume(new Node("127.0.0.1", environment))
  .get();
</code></pre>

<p>  }</p>

<p>  public void write(final Buffer data) {</p>

<pre><code>final Operation&lt;Event&lt;Buffer&gt;&gt; op = writeProcessor.get();
op.get().setData(data);
op.commit();
</code></pre>

<p>  }</p>

<p>}
```</p>

<p>One final note before we move on: did you spot the <code>Environment</code> here? This is also a common theme in the Reactor framework. The <code>Environment</code> is used in many places to signal information about &ndash; who would have thought that &ndash; the JVM environment. The general recommendation is to create only one <code>Environment</code> instance per JVM, so we happily pass it around in our small application.</p>

<h2>The Consumer</h2>

<p>Before we get into the nitty-gritty network details, let&rsquo;s add a consumer that just prints out the data that he &ldquo;sees&rdquo;. If you want to try this sample, make sure to change the previous code temporarily from <code>.consume(new Node(...))</code> to <code>.consume(new EchoConsumer())</code>.</p>

<p>``` java
public class EchoConsumer implements Consumer&lt;Event<Buffer>> {</p>

<p>  @Override
  public void accept(final Event<Buffer> bufferEvent) {</p>

<pre><code>System.out.println(Arrays.toString(bufferEvent.getData().asBytes()));
</code></pre>

<p>  }</p>

<p>}
```</p>

<p>The <code>accept</code> method is always called once there is information available on the Processor. Let&rsquo;s add a simple test case to verify that this works:</p>

<p>``` java
import org.junit.Test;
import reactor.io.Buffer;</p>

<p>public class MessageDispatcherTest {</p>

<p>  @Test
  public void echoSomeGarbage() {</p>

<pre><code>MessageDispatcher dispatcher = new MessageDispatcher();
dispatcher.write(Buffer.wrap("Hello World!"));
</code></pre>

<p>  }</p>

<p>}
```</p>

<p>Now if we run this test, we should see <code>[72, 101, 108, 108, 111, 32, 87, 111, 114, 108, 100, 33]</code> printed on the console &ndash; great! This is the byte array representation of our wrapped buffer. Of course we could make our lives easier and use <code>Strings</code> instead of <code>Buffer</code> in our implementation, but the <code>Buffer</code> works much better with network communication.</p>

<p>The next step would be to send the data over the network. Let&rsquo;s replace our Consumer with a more intelligent one. Be aware that the <code>TcpClient</code> that you&rsquo;ll see doesn&rsquo;t communicate with Java NIO directly &ndash; it makes use of the excellent <a href="http://netty.io/">Netty</a> project which provides a convenient and performant wrapper around NIO and OIO (we use NIO here).</p>

<p>``` java
public class Node implements Consumer&lt;Event<Buffer>> {</p>

<p>  private final TcpClient&lt;Buffer, Buffer> client;
  private TcpConnection&lt;Buffer, Buffer> conn = null;</p>

<p>  public Node(String hostname, Environment env) {</p>

<pre><code>client = new TcpClientSpec&lt;Buffer, Buffer&gt;(NettyTcpClient.class)
  .env(env)
  .connect(hostname, 11210)
  .get();

try {
  conn = client.open().await();
} catch (InterruptedException e) {
  e.printStackTrace();
}
</code></pre>

<p>  }</p>

<p>  @Override
  public void accept(final Event<Buffer> bufferEvent) {</p>

<pre><code>Buffer buf = bufferEvent.getData();

final CountDownLatch latch = new CountDownLatch(1);
conn.send(buf, new Consumer&lt;Boolean&gt;() {
  @Override
  public void accept(final Boolean success) {
    latch.countDown();
  }
});

try {
  latch.await(1, TimeUnit.SECONDS);
} catch (final Exception ex) {
  throw new RuntimeException("Something went wrong while waiting :(", ex);
}
</code></pre>

<p>  }</p>

<p>}
```</p>

<p>While this might seem like a lot of code, it&rsquo;s not so bad. We do two things here. During object construction, we create a new <code>TcpClient</code> through the <code>TcpClientSpec</code> (see the Spec again?) and pass it the environment and the socket to connect to. The next thing we need to do is actually open the connection and wait until finished.</p>

<p>Now that we have an open connection, we can write to it. Since everything is non-blocking in Reactor, so is socket writing. In order to not overwhelm the underlying infrastructure, we have to wait until it is actually finished before moving on to handle the next <code>Event</code> in the Processor. We do this by using a <code>CountDownLatch</code>, which will be counted down once the writing has finished. In our simple example we just fail if it took longer than one second. In a real application, one could report errors or retry with Backoff.</p>

<p>Before we can run that code, we need to add a test case to make it all work.</p>

<p>``` java
Buffer[] buffers = new Buffer[10];</p>

<p>@Before
public void initBuffers() {</p>

<pre><code>for (int i = 0; i &lt; 10; i++)  {
    Buffer buf = new Buffer(30, false);
    buf.append((byte)0x80); // Magic Byte
    buf.append((byte)0x09); // GETQ Opcode
    buf.append(new byte[] {0x00, 0x03}); // 3 byte keylength (KEY)
    buf.append((byte)0x00); // Extra Length
    buf.append((byte)0x00); // data type
    buf.append(new byte[] {0x00, 0x00}); // reserved
    buf.append(new byte[] {0x00, 0x00, 0x00, 0x03}); // total body size
    buf.append(new byte[] {0x00, 0x00, 0x00, 0x00}); // Opaque
    buf.append(new byte[] {0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00}); // CAS
    buf.append(new byte[] {0x65, 0x6F, (byte)(i % 9)});
    buffers[i] = buf;
}
</code></pre>

<p>}</p>

<p>@Test
public void giveItSomeLoad() {</p>

<pre><code>MessageDispatcher dispatcher = new MessageDispatcher();

long amountOfOps = 100000000;
for (long i = 0; i &lt; amountOfOps; i++) {
    dispatcher.write(new Buffer(buffers[(int)(i % 9)]).flip());
}
</code></pre>

<p>}
```</p>

<p>To actually simulate something real, this test creates ten buffer instances with Couchbase messages. Those familiar with the memcached binary protocol can identify it as a GETQ request. This means it does not return anything when the key is not found (which is what we want, because in this case we want to benchmark the upper limit for write throughput and not concern us with parsing of error responses). Once the data is created, we run a given amount of operations and call the <code>write</code> method on the <code>MessageDispatcher</code>.</p>

<h2>Batch all the things!</h2>

<p>If we run this, we get a &ndash; very disappointing &ndash; number of only 50K ops/s. In addition, we get lots of CPU usage on the Java process (100% and more on a quad core processor here). Why is it so slow? The answer is: network overhead. In our case, we send out 27 byte chunks over the network. With all the TCP, IP and Ethernet headers, there is lots of unnecessary overhead involved that puts down our performance. The answer to that is batching! If our producers are faster than the consumers, we can batch the intermediate data up into a buffer and send it over the wire in one chunk. This will give us a much better goodput ratio.</p>

<p>To help us with batching the Disruptor and the Processor expose the start end end of a batching phase to our consumer. To get this information, we need to extend from the <code>BatchConsumer</code> instead of the regular <code>Consumer</code>. Let&rsquo;s refactor our node and add some batching characteristics:</p>

<p>``` java
public class BatchingNode implements BatchConsumer&lt;Event<Buffer>> {</p>

<p>  private final TcpClient&lt;Buffer, Buffer> client;
  private TcpConnection&lt;Buffer, Buffer> conn = null;
  private Buffer writeBuffer;</p>

<p>  public BatchingNode(String hostname, Environment env) {</p>

<pre><code>client = new TcpClientSpec&lt;Buffer, Buffer&gt;(NettyTcpClient.class)
  .env(env)
  .connect(hostname, 11210)
  .get();

try {
  conn = client.open().await();
} catch (InterruptedException e) {
  e.printStackTrace();
}

writeBuffer = new Buffer(1500, true);
</code></pre>

<p>  }</p>

<p>  @Override
  public void start() {
  }</p>

<p>  @Override
  public void end() {</p>

<pre><code>flush();
</code></pre>

<p>  }</p>

<p>  @Override
  public void accept(final Event<Buffer> bufferEvent) {</p>

<pre><code>Buffer buf = bufferEvent.getData();

if (writeBuffer.remaining() &lt;= buf.remaining()) {
  flush();
}

writeBuffer.append(buf);
</code></pre>

<p>  }</p>

<p>  private void flush() {</p>

<pre><code>final CountDownLatch latch = new CountDownLatch(1);
writeBuffer.flip();
conn.send(writeBuffer, new Consumer&lt;Boolean&gt;() {
  @Override
  public void accept(final Boolean success) {
    latch.countDown();
  }
});
try {
  latch.await(1, TimeUnit.SECONDS);
} catch (final Exception ex) {
  throw new RuntimeException("got ex", ex);
}
writeBuffer.clear();
</code></pre>

<p>  }</p>

<p>}
```</p>

<p>The code here is not much different. Note that we refactored the writing part out into the <code>flush</code> method. In the <code>accept</code> method, we write to the network if the buffer is full, otherwise we just add it to our write buffer. Note that we also need to <code>flush</code> if the batching is over (notified through the <code>end</code> method), otherwise we would potentially keep data around for a longer time than needed (and latency is still important to us).</p>

<p>Let&rsquo;s run the test case again&hellip; now we get 500k ops/s with only 40% CPU load on the java process! Now that&rsquo;s what I call an improvement!</p>

<h2>Summary</h2>

<p>This was a very quick introduction into the Processor, just one piece in the very promising Reactor framework. There is so much more to blog about in the future, so stay tuned!</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Useful Couchbase Resources & Blog Posts]]></title>
    <link href="http://daschl.github.io/Useful-Couchbase-Resources-Blog-Posts"/>
    <updated>2013-08-06T14:49:48+02:00</updated>
    <id>http://daschl.github.io/Useful-Couchbase-Resources-Blog-Posts</id>
    <content type="html"><![CDATA[<p>The following list is a convenient way to get access to lots of resources, blog posts and material that have been shared throughout the past months. I tried to separate them by area, but of course lots of them overlap to some extent.</p>

<p>They are sorted by date (so you&rsquo;ll find the most recent ones on top) and include the author where possible. Be aware that some of the older articles may already be outdated  or not 100% accurate.</p>

<p>I&rsquo;ll try to update this page as new articles get published, so it may pay off to come back here from time to time and check out the topmost ones. If you want to see your article included, post them in the comments!</p>

<h2>Starting Out</h2>

<ul>
<li><a href="http://www.couchbase.com/docs/couchbase-manual-2.1.0/">Official Couchbase Server 2.1 Manual</a>: The official manual and a good starting point for all kinds of general-purpose and architectural questions.</li>
<li><a href="http://www.couchbase.com/docs/couchbase-devguide-2.1.0/">Couchbase Server 2.1 Developer Guide</a>: The developer guide is particularly useful for developers that are new to document modeling and general app-related questions.</li>
<li><a href="http://www.couchbase.com/communities">The Community Portal</a>: Starting point for all SDK-related questions and links.</li>
<li>2013-04-24 <a href="http://blog.couchbase.com/top-10-things-ops-sys-admin-must-know-about-couchbase">Top 10 things an Ops / Sys admin must know about Couchbase</a>: Ten short rules that sys admins that maintain Couchbase clusters should keep in mind.</li>
<li>2012-07-06 <a href="http://tugdualgrall.blogspot.co.at/2012/07/couchbase-101-install-store-and-query.html">Couchbase 101 : Install, Store and Query Data (tgrall)</a>: A very basic introduction for people starting out, teaching the very basics in a hands-on fashion.</li>
</ul>


<h2>Installation &amp; Infrastructure</h2>

<ul>
<li><a href="http://www.couchbase.com/docs/couchbase-manual-2.1.0/couchbase-getting-started.html">Official Installation Guide for 2.1</a>: The official installation guide, read this before installing on production systems.</li>
<li>2013-08-05 <a href="http://trondn.blogspot.no/2013/08/running-couchbase-211-on-smartos.html">Running Couchbase 2.1.1 on SmartOS (trondn)</a>: Learn how to &ndash; step by step &ndash; compile and run a Couchbase cluster on SmartOS. This is for all the Solaris fans out there!</li>
<li>2013-07-22 <a href="http://blog.couchbase.com/deploying-couchbase-chef">Deploying Couchbase with Chef (ketakigangal)</a>: If you use Chef to automate your infrastructure, this blog post shows you how to integrate Couchbase with it.</li>
<li>2013-07-11 <a href="http://tugdualgrall.blogspot.co.at/2013/07/deploy-your-nodecouchbase-application.html">Deploy your Node/Couchbase application to the cloud with Clever Cloud (tgrall)</a>: You&rsquo;ll learn how to deploy your Node.JS app with Couchbase onto &ldquo;clever cloud&rdquo;, a PaaS provider.</li>
<li>2013-06-27 <a href="http://www.ebruakagunduz.com/2013/06/nagios-plugin-to-monitor-couchbase.html?spref=tw">Nagios plugin to monitor Couchbase (Ebru Akagündüz)</a>: If you are using Nagios to monitor your infrastructure, this post shows you how to integrate Couchbase with a single plugin.</li>
<li>2013-05-31 <a href="http://tugdualgrall.blogspot.co.at/2013/05/create-couchbase-cluster-in-one-command.html">Create a Couchbase cluster in less than a minute with Ansible (tgrall)</a>: Create a Couchbase cluster automatically with Ansible, a systems automation framework like chef.</li>
<li>2013-05-27 <a href="http://nitschinger.at/A-Couchbase-Cluster-in-Minutes-with-Vagrant-and-Puppet">A Couchbase Cluster in Minutes with Vagrant and Puppet (daschl)</a>: If you want to setup a 4 node cluster with couchbase in minutes, this blog post shows you how to do it.</li>
</ul>


<h2>Document Design &amp; Data Import/Export</h2>

<ul>
<li>2013-07-18 <a href="http://tugdualgrall.blogspot.co.at/2013/07/how-to-implement-document-versioning.html">How to implement Document Versioning with Couchbase (tgrall)</a>: See how to implement document versioning by using a key-based approach. Uses the Java SDK, but can be adapted for all languages.</li>
<li>2013-07-08 <a href="http://dev.theladders.com/2013/07/denormalize-the-datas-for-great-good">Denormalize the Datas for Great Good (John Connolly)</a>: See how TheLadders benefited from denormalizing its dataset and using Couchbase, greatly reducing their response times.</li>
<li>2013-07-03 <a href="http://tugdualgrall.blogspot.co.at/2013/07/sql-to-nosql-importing-data-from-rdbms.html">SQL to NoSQL : Copy your data from MySQL to Couchbase (tgrall)</a>: A Java-based tool to import data from a SQL database into Couchbase.</li>
</ul>


<h2>Views</h2>

<ul>
<li>2013-07-25 <a href="http://blog.couchbase.com/caching-queries-couchbase-high-performance">Caching queries in Couchbase for high performance (Alexis Roos)</a>: Learn how to cache view results for better performance.</li>
<li>2013-07-12 <a href="http://blog.couchbase.com/calculating-average-document-size-documents-stored-couchbase">Calculating average document size of documents stored in Couchbase. (Alexis Roos)</a>: With a simple map and a custom reduce function, one can easily calculate the average document size in the bucket.</li>
<li>2013-06-14 <a href="http://avsej.net/2013/analyzing-binary-data-in-couchbase">Analyzing Binary Data in Couchbase (avsej)</a>: Shows how to access binary (non-json) data from a View. Uses ruby to store the data, but can be adapted to any language.</li>
<li>2013-02-18 <a href="http://tugdualgrall.blogspot.co.at/2013/02/how-to-get-latest-document-by-datetime.html">How to get the latest document by date/time field (tgrall)</a>: A simple example on how to sort View-data based on a timestamp.</li>
<li>2013-02-13 <a href="http://tugdualgrall.blogspot.co.at/2013/02/introduction-to-collated-views-with.html">Introduction to Collated Views with Couchbase 2.0 (tgrall)</a>: Views can also be used to output &ldquo;master/detail&rdquo;-like scenarios. This post shows how.</li>
</ul>


<h2>Java SDK &amp; JVM</h2>

<ul>
<li><a href="http://www.couchbase.com/communities/java/getting-started">Getting Started &amp; Download</a>: The official &ldquo;Getting Started&rdquo; page for the Java SDK. Introduction, Tutorial and Downloads.</li>
<li>2013-05-16 <a href="http://nitschinger.at/Logging-with-the-Couchbase-Java-Client">Logging with the Couchbase Java Client (daschl)</a>: An in-depth post about how to correctly configure logging for the Java SDK (and the underlying spymemcached library).</li>
<li>2013-04-17 <a href="http://nitschinger.at/Couchbase-Java-SDK-Internals">Couchbase Java SDK Internals (daschl)</a>: A very detailed post about the inner workings of the Java SDK. Recommended for advanced users who want to understand more of the internals.</li>
<li>2012-12-30 <a href="http://tugdualgrall.blogspot.co.at/2012/12/couchbase-101-create-views-mapreduce.html">Couchbase 101: Create views (MapReduce) from your Java application (tgrall)</a>: How to create views and design documents directly from the Java SDK.</li>
<li>2012-11-05 <a href="http://tugdualgrall.blogspot.co.at/2012/11/couchbase-create-large-dataset-using.html">Couchbase : Create a large dataset using Twitter and Java (tgrall)</a>: Feed data from Twitter directly into your Couchbase cluster through the Java SDK.</li>
<li>2012-04-26 <a href="http://nitschinger.at/Accessing-Couchbase-from-Scala">Accessing Couchbase from Scala (daschl)</a>: How to access the Couchbase Java SDK from the Scala programing language.</li>
</ul>


<h2>.NET</h2>

<ul>
<li><a href="http://www.couchbase.com/communities/net/getting-started">Getting Started &amp; Download</a>: The official &ldquo;Getting Started&rdquo; page for the .NET SDK. Introduction, Tutorial and Downloads.</li>
<li>2013-06-14 <a href="http://vimeo.com/68378224">Video: Code-First NoSQL with .NET and Couchbase (John Zablocki)</a>: A video where John Zablocki gives an introduction into NoSQL development and especially with Couchbase.</li>
<li>2013-03-06 <a href="http://blog.couchbase.com/net-couchbase-client-instrumentation-aspnet-and-glimpse">.NET Couchbase Client Instrumentation with ASP.NET and Glimpse (John Zablocki)</a>: See how to get your Couchbase server-side logging errors easily displayed in the browser console. Very helpful during development.</li>
<li>2013-02-01 <a href="http://blog.couchbase.com/moving-no-schema-stack-c-and-dynamic-types">Moving No Schema up the Stack with C# and Dynamic Types (John Zablocki)</a>: This blog post shows how to store schemaless data with both dictionaries and C#&rsquo;s dynamic typing.</li>
<li>2013-01-04 <a href="http://blog.couchbase.com/xdcr-aspnet-and-nancy">XDCR with ASP.NET and Nancy (John Zablocki)</a>: Learn how to build an XDCR endpoint (like ElasticSearch integration) and read the data through our XDCR mechanisms.</li>
<li>2012-10-23 <a href="http://blog.couchbase.com/using-c-domain-objects-define-couchbase-views">Using C# Domain Objects to Define Couchbase Views (John Zablocki)</a>: How to automatically create DesignDocuments based of C# domain objects.</li>
<li>2012-10-05 <a href="http://blog.couchbase.com/new-visual-studio-code-snippets-net-couchbase-client-library">New Visual Studio Code Snippets for the .NET Couchbase Client Library (John Zablocki)</a>: A collection of helpful snippets in the day-to-day development process.</li>
<li>2012-09-20 <a href="http://blog.couchbase.com/strongly-typed-views-net-client-library">Strongly Typed Views with the .NET Client Library (John Zablocki)</a>: Learn how to map View responses directly onto domain objects.</li>
<li>2012-08-01 <a href="http://blog.couchbase.com/introducing-couchbase-aspnet-outputcache-provider">Introducing the Couchbase ASP.NET OutputCache Provider (John Zablocki)</a>: A short post on how to use Couchbase for easy caching in the ASP.NET environment.</li>
</ul>


<h2>PHP</h2>

<p>(Note: some of these posts are outdated in the way that currently the &ldquo;way to go&rdquo; when installing the PHP SDK is through PECL. See the the <a href="http://www.couchbase.com/communities/php/getting-started">Getting Started &amp; Download</a> guide for more information.)</p>

<ul>
<li><a href="http://www.couchbase.com/communities/php/getting-started">Getting Started &amp; Download</a>: The official &ldquo;Getting Started&rdquo; page for the PHP SDK. Introduction, Tutorial and Downloads.</li>
<li>2013-04-02  <a href="http://trondn.blogspot.co.at/2013/04/couchbase-php-xampp-and-windows.html">Couchbase, PHP, XAMPP and Windows (trondn)</a>: A short post on how to use the PHP SDK from Microsoft Windows.</li>
<li>2013-04-01 <a href="http://trondn.blogspot.co.at/2013/04/building-couchbase-php-driver-on-ubuntu.html">Building Couchbase PHP driver on Ubuntu (trondn)</a>: Learn how to build the Couchbase driver on Ubuntu and use it in a simple program.</li>
<li>2013-02-04 <a href="http://trondn.blogspot.co.at/2013/02/accessing-couchbase-from-php-on-your-mac.html">Accessing Couchbase from PHP on your Mac! (trondn)</a> Building and running the SDK on your Mac is easy, learn how to do it in this post.</li>
<li>2012-11-01 <a href="http://trondn.blogspot.co.at/2012/11/building-php-extension-for-couchbase-on.html">Building the PHP extension for Couchbase on Microsoft Windows! (trondn)</a>: Learn how to compile the SDK on Windows using Visual Studio 2008.</li>
<li>2012-06-25 <a href="http://nitschinger.at/How-to-store-PHP-sessions-in-Couchbase">How to store PHP sessions in Couchbase (daschl)</a>: This post shows how to store PHP sessions in Couchbase using different mechanims (not only the official SDK).</li>
<li>2012-06-21 <a href="http://nitschinger.at/Using-Couchbase-as-a-flexible-session-store">Using Couchbase as a flexible session store (daschl)</a>: With Couchbase Server 2.0, JSON data and Views, its easy to run metrics over your sessions and identify user behavior. Learn how in this post.</li>
</ul>


<h2>C &amp; Go</h2>

<ul>
<li><a href="http://www.couchbase.com/communities/c/getting-started">Getting Started &amp; Download with the C SDK</a>: The official &ldquo;Getting Started&rdquo; page for the C SDK. Introduction, Tutorial and Downloads.</li>
<li><a href="https://github.com/couchbaselabs/go-couchbase">Official Go Client Repository</a>: The Go repository with code and simple examples.</li>
</ul>


<h2>Ruby</h2>

<ul>
<li><a href="http://www.couchbase.com/communities/ruby/getting-started">Getting Started &amp; Download</a>: The official &ldquo;Getting Started&rdquo; page for the Ruby SDK. Introduction, Tutorial and Downloads.</li>
<li>2013-02-23 <a href="http://avsej.net/links/2013/couchbase-and-rails/">Couchbase and Rails Talk (avsej)</a>: A presentation by our lead Ruby SDK developer on how to integrate it with Ruby on Rails.</li>
<li>2013-02-11 <a href="http://blog.couchbase.com/using-couchbase-ruby-gem-eventmachine">Using Couchbase Ruby Gem with EventMachine (avsej)</a>: This post shows how to use the Ruby SDK together with the high performance EventMachine (custom protocols and performance for TCP/IP) gem.</li>
</ul>


<h2>Node.JS</h2>

<ul>
<li>2013-03-06 <a href="http://tugdualgrall.blogspot.co.at/2013/03/easy-application-development-with.html">Easy application development with Couchbase, Angular and Node (tgrall)</a>: Storing Ideas and Votes in Couchbase with Angular and NodeJS.</li>
<li>2013-01-04 <a href="http://tugdualgrall.blogspot.co.at/2013/01/getting-started-with-couchbase-and.html">Getting started with Couchbase and node.js on Windows (tgrall)</a>: How to install and use the NodeJS Couchbase client library on Windows.</li>
<li>2012-11-13 <a href="http://tugdualgrall.blogspot.co.at/2012/11/building-chat-application-using-nodejs.html">Building a chat application using Node.js and Couchbase (tgrall)</a>: A nice chat application using Couchbase, NodeJS and socket.io for &ldquo;real time&rdquo; feeling.</li>
<li>2012-09-24 <a href="http://tugdualgrall.blogspot.co.at/2012/09/create-simple-nodejs-and-couchbase.html">Create a Simple Node.js and Couchbase application&hellip; on OS X (tgrall)</a> A simple (but maybe outdated) tutorial on how to use the NodeJS driver from OSX.</li>
</ul>


<h2>Python</h2>

<ul>
<li><a href="http://www.couchbase.com/communities/python/getting-started">Getting Started &amp; Download</a>: The official &ldquo;Getting Started&rdquo; page for the Python SDK. Introduction, Tutorial and Downloads.</li>
<li>2013-06-21 <a href="http://mnunberg.github.io/2013/python-extension-windows-binaries">Python Extension Windows Binaries (mnunberg)</a>: A tale by our maintainer of the Python SDK on how to upload Windows binaries to PyPi.</li>
<li>2013-05-30 <a href="http://blog.couchbase.com/whats-python-couchbase-sdk">What&rsquo;s up with the Python Couchbase SDK (volker)</a>: A rundown of the latest changes on the Python SDK.</li>
</ul>


<h2>Ecosystem</h2>

<ul>
<li>2013-07-31 <a href="http://www.ortussolutions.com/blog/couchbase-cluster-setup-orm-secondary-cache-introduction">Couchbase: Cluster Setup + ORM Secondary Cache Introduction (Brad Wood)</a>: Using ColdFusion and looking for a secondary cache implementation? Look no further.</li>
<li>2013-07-22 <a href="http://blog.jeroenreijn.com/2013/07/visitor-analysis-with-couchbase-elasticsearch.html">Real-time visitor analysis with Couchbase, Elasticsearch and Kibana (Jeroen Reijn)</a>: A great post on a customer&rsquo;s use case for real-time visitor analysis.</li>
</ul>


<h2>Troubleshooting</h2>

<ul>
<li><a href="http://www.couchbase.com/docs/couchbase-manual-2.1.0/couchbase-troubleshooting.html">Official troubleshooting Guide</a>: The best place to start if something goes wrong on the server and you don&rsquo;t know why.</li>
<li>2012-12-26 <a href="http://tugdualgrall.blogspot.co.at/2012/12/what-to-do-if-your-couchbase-server.html">What to do if your Couchbase Server does not start? (tgrall)</a>: If you have troubles getting older Couchbase Server 2.0 versions to run on Windows, this post is for you.</li>
</ul>


<h2>Fun Stuff</h2>

<ul>
<li><a href="https://github.com/couchbaselabs/DeveloperDay">Example code for lots of SDKs and Languages</a>: Our DeveloperDay material with hands-on code examples to try and learn.</li>
<li>2013-06-18 <a href="http://nitschinger.at/Fun-with-Couchbase-Views-and-Message-Pack">Fun with Couchbase Views and MessagePack (daschl)</a>: While JSON is tried and true, with a little twiggling and some fun you can get Couchbase Views to speak MessagePack!</li>
<li>2013-04-29 <a href="http://tugdualgrall.blogspot.co.at/2013/04/screencast-fun-with-couchbase-mapreduce.html">Screencast : Fun with Couchbase, MapReduce and Twitter (tgrall)</a>: A Screencast on importing Twitter data into Couchbase and analyzing it on the fly through Views.</li>
</ul>


<p>Last Updated: 2013-08-06 (daschl)</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Fun With Couchbase Views and MessagePack]]></title>
    <link href="http://daschl.github.io/Fun-with-Couchbase-Views-and-Message-Pack"/>
    <updated>2013-06-18T14:49:48+02:00</updated>
    <id>http://daschl.github.io/Fun-with-Couchbase-Views-and-Message-Pack</id>
    <content type="html"><![CDATA[<p>Alright, before we start I have to admit that this is a little bit of a hack. Not that it doesn&rsquo;t work, but of course Couchbase Server 2.0 officially only supports JSON documents to be queried through Views. In addition to that, it is not so much known that you have access to all the other documents through Base64 encoding. Recently, <a href="http://avsej.net/2013/analyzing-binary-data-in-couchbase/">Sergey</a> showed us how to very easily analyze binary data in Couchbase Views and this brought me on the idea to take it one step further.</p>

<p>In this blog post we&rsquo;re going to store <a href="http://msgpack.org/">MessagePack</a> formatted data in Couchbase and then make its content available to Views (and allow us to query it). Note that you don&rsquo;t need to patch Couchbase for this, its just a snippet of JavaScript code that you need to include in your map function. We&rsquo;ll be using Java on the client side here, but nearly every combination of our official SDKs and MessagePack modules works for this.</p>

<h2>Storing the Data</h2>

<p>In order to store something meaningful we can query later, let&rsquo;s create a Maven project with all needed dependencies. Note that I&rsquo;m assuming you have a Couchbase Server installation running and are familiar with the Couchbase Java SDK (at least a little bit). Also I won&rsquo;t cover the View fundamentals since this is a little advanced topic.</p>

<p>Here are the required dependencies to start with the fun:</p>

<p>``` xml
<dependencies></p>

<pre><code>&lt;dependency&gt;
    &lt;groupId&gt;couchbase&lt;/groupId&gt;
    &lt;artifactId&gt;couchbase-client&lt;/artifactId&gt;
    &lt;version&gt;1.1.7&lt;/version&gt;
&lt;/dependency&gt;
&lt;dependency&gt;
    &lt;groupId&gt;org.msgpack&lt;/groupId&gt;
    &lt;artifactId&gt;msgpack&lt;/artifactId&gt;
    &lt;version&gt;0.6.7&lt;/version&gt;
&lt;/dependency&gt;
</code></pre>

<p></dependencies>
```</p>

<p>Also, don&rsquo;t forget that the Couchbase SDK lives in its own repository:</p>

<p>``` xml
<repository></p>

<pre><code>&lt;id&gt;couchbase&lt;/id&gt;
&lt;name&gt;Couchbase Maven Repository&lt;/name&gt;
&lt;url&gt;http://files.couchbase.com/maven2/&lt;/url&gt;
&lt;snapshots&gt;
    &lt;enabled&gt;false&lt;/enabled&gt;
&lt;/snapshots&gt;
</code></pre>

<p></repository>
```</p>

<p>Now, we can create a simple script that connects to Couchbase, creates some HashMaps with meaningful content, encodes them with the MessagePack encoder and stores them in the database:</p>

<p>``` java
import com.couchbase.client.CouchbaseClient;
import org.msgpack.MessagePack;</p>

<p>import java.net.URI;
import java.util.Arrays;
import java.util.HashMap;</p>

<p>public class Main {</p>

<p>  public static void main(String[] args) throws Exception {</p>

<pre><code>// Connect to Couchbase
CouchbaseClient cb = new CouchbaseClient(Arrays.asList(new URI("http://127.0.0.1:8091/pools")), "default", "");

// Init MessagePack
MessagePack msgpack = new MessagePack();

// Create a few Documents with some content
HashMap&lt;String, String&gt; user1 = new HashMap&lt;String, String&gt;();
user1.put("firstname", "Michael");
user1.put("lastname", "Nitschinger");

HashMap&lt;String, String&gt; user2 = new HashMap&lt;String, String&gt;();
user2.put("firstname", "Matt");
user2.put("lastname", "Ingenthron");

HashMap&lt;String, String&gt; user3 = new HashMap&lt;String, String&gt;();
user3.put("firstname", "Sergey");
user3.put("lastname", "Avseyev");

// Encode and store them
cb.set("user:michael", msgpack.write(user1)).get();
cb.set("user:matt", msgpack.write(user2)).get();
cb.set("user:sergey", msgpack.write(user3)).get();

// Close the Connection
cb.shutdown();
</code></pre>

<p>  }</p>

<p>}
```</p>

<p>The only new part to Couchbase folks is the &ldquo;MessagePack&rdquo; code. You create a new instance of <code>MessagePack</code> and then pass the data to the <code>write</code> method. I&rsquo;m not an expert on this library, but it looks like you can also make it work with generic POJOs, which would be something to look into if you model an actual application with it.</p>

<h2>Querying the Data</h2>

<p>Now if we run the code, we&rsquo;ll see that three documents have been persisted, but they show up as binary. That&rsquo;s because its not JSON and kind of expected. Now, go create a View on your bucket and start out with an empty map function like this:</p>

<p><code>javascript
function(doc, meta) {
  emit(doc, null);
}
</code></p>

<p>If you query it, you&rsquo;ll see the document keys emitted like <code>gqhsYXN0bmFtZadBdnNleWV2qWZpcnN0bmFtZaZTZXJnZXk</code>, which is <a href="http://en.wikipedia.org/wiki/Base64">Base64</a> encoding. Now, let&rsquo;s change the view function a bit and use the built-in <code>decodeBase64</code> method:</p>

<p><code>javascript
function(doc, meta) {
  emit(decodeBase64(doc), null);
}
</code></p>

<p>Now your output looks more like <code>[130,168,108,97,115,116,110,97,109,...121]</code>, which is the native format of MessagePack! You would also see the same output if you take the result of <code>msgpack.write()</code> and print out the byte array properly.</p>

<p>The first step is done, we have direct access to the stored data. Now we need to decode it. The good news is that there is a JavaScript library for MessagePack, but it doesn&rsquo;t work out of the box with our view code. The library does lots of browser stuff which we don&rsquo;t have in the environment. <a href="https://raw.github.com/msgpack/msgpack-javascript/master/msgpack.js">here</a> is the link to the original library.</p>

<p>Now, after some fiddling with the code and removing unneeded parts (but actually not changing how it works), I ended up with something that works. You can go ahead and grab the full snippet <a href="https://gist.github.com/daschl/5796263">here</a>. Personally, I prefer to have my map functions short and sweet, so here is the same code, but <a href="https://gist.github.com/daschl/5796268">minified</a>.</p>

<p>Now, we can plug this code into our map function and use the method to decode our data on the fly:</p>

<p>``` javascript
function(doc, meta) {</p>

<pre><code>/*!{id:msgpack.js,ver:1.05,license:"MIT",author:"uupaa.js@gmail.com"}*/
/* Modified by @daschl and @avsej to strip out whats not needed */
var msgunpack=function(){function k(){var g,d,e,b=0,f,h,c=m;d=c[++a];if(224&lt;=d)return d-256;if(192&gt;d){if(128&gt;d)return d;144&gt;d?(b=d-128,d=128):160&gt;d?(b=d-144,d=144):(b=d-160,d=160)}switch(d){case 192:return null;case 194:return!1;case 195:return!0;case 202:return b=16777216*c[++a]+(c[++a]&lt;&lt;16)+(c[++a]&lt;&lt;8)+c[++a],f=b&gt;&gt;23&amp;255,h=b&amp;8388607,!b||2147483648===b?0:255===f?h?NaN:Infinity:(b&amp;2147483648?-1:1)*(h|8388608)*Math.pow(2,f-127-23);case 203:b=16777216*c[++a]+(c[++a]&lt;&lt;16)+(c[++a]&lt;&lt;8)+c[++a];d=b&amp;2147483648;
f=b&gt;&gt;20&amp;2047;h=b&amp;1048575;if(!b||2147483648===b)return a+=4,0;if(2047===f)return a+=4,h?NaN:Infinity;b=16777216*c[++a]+(c[++a]&lt;&lt;16)+(c[++a]&lt;&lt;8)+c[++a];return(d?-1:1)*((h|1048576)*Math.pow(2,f-1023-20)+b*Math.pow(2,f-1023-52));case 207:return b=16777216*c[++a]+(c[++a]&lt;&lt;16)+(c[++a]&lt;&lt;8)+c[++a],4294967296*b+16777216*c[++a]+(c[++a]&lt;&lt;16)+(c[++a]&lt;&lt;8)+c[++a];case 206:b+=16777216*c[++a]+(c[++a]&lt;&lt;16);case 205:b+=c[++a]&lt;&lt;8;case 204:return b+c[++a];case 211:return b=c[++a],b&amp;128?-1*(72057594037927936*(b^255)+
281474976710656*(c[++a]^255)+1099511627776*(c[++a]^255)+4294967296*(c[++a]^255)+16777216*(c[++a]^255)+65536*(c[++a]^255)+256*(c[++a]^255)+(c[++a]^255)+1):72057594037927936*b+281474976710656*c[++a]+1099511627776*c[++a]+4294967296*c[++a]+16777216*c[++a]+65536*c[++a]+256*c[++a]+c[++a];case 210:return b=16777216*c[++a]+(c[++a]&lt;&lt;16)+(c[++a]&lt;&lt;8)+c[++a],2147483648&gt;b?b:b-4294967296;case 209:return b=(c[++a]&lt;&lt;8)+c[++a],32768&gt;b?b:b-65536;case 208:return b=c[++a],128&gt;b?b:b-256;case 219:b+=16777216*c[++a]+(c[++a]&lt;&lt;
16);case 218:b+=(c[++a]&lt;&lt;8)+c[++a];case 160:f=[];d=a;for(g=d+b;d&lt;g;)e=c[++d],f.push(128&gt;e?e:224&gt;e?(e&amp;31)&lt;&lt;6|c[++d]&amp;63:(e&amp;15)&lt;&lt;12|(c[++d]&amp;63)&lt;&lt;6|c[++d]&amp;63);a=d;return 10240&gt;f.length?l.apply(null,f):n(f);case 223:b+=16777216*c[++a]+(c[++a]&lt;&lt;16);case 222:b+=(c[++a]&lt;&lt;8)+c[++a];case 128:for(h={};b--;){g=c[++a]-160;f=[];d=a;for(g=d+g;d&lt;g;)e=c[++d],f.push(128&gt;e?e:224&gt;e?(e&amp;31)&lt;&lt;6|c[++d]&amp;63:(e&amp;15)&lt;&lt;12|(c[++d]&amp;63)&lt;&lt;6|c[++d]&amp;63);a=d;h[l.apply(null,f)]=k()}return h;case 221:b+=16777216*c[++a]+(c[++a]&lt;&lt;16);case 220:b+=
(c[++a]&lt;&lt;8)+c[++a];case 144:for(f=[];b--;)f.push(k());return f}}function n(a){try{return l.apply(this,a)}catch(d){}for(var e=[],b=0,f=a.length,h=p;b&lt;f;++b)e[b]=h[a[b]];return e.join("")}var j={},p={},m=[],a=0,l=String.fromCharCode;return function(g){var d;if("string"===typeof g){d=[];var e=g.split(""),b=-1,f;f=e.length;for(g=f%8;g--;)++b,d[b]=j[e[b]];for(g=f&gt;&gt;3;g--;)d.push(j[e[++b]],j[e[++b]],j[e[++b]],j[e[++b]],j[e[++b]],j[e[++b]],j[e[++b]],j[e[++b]])}else d=g;m=d;a=-1;return k()}}();

var obj = msgunpack(decodeBase64(doc));
if(obj.firstname) {
    emit(obj.firstname, null);
}
</code></pre>

<p>}
```</p>

<p>This map function decodes our MessagePack data and just emits the value with key &ldquo;firstname&rdquo;. Once you query this view, you&rsquo;ll see stuff like this emitted:</p>

<p>``` javascript
{</p>

<pre><code>total_rows: 3,
rows: [{
    id: "user:matt",
    key: "Matt",
    value: null
},{
    id: "user:michael",
    key: "Michael",
    value: null
},{
    id: "user:sergey",
    key: "Sergey",
    value: null
}]
</code></pre>

<p>}
```</p>

<p>Isn&rsquo;t that lovely? We can now query this view from our Java SDK and use the MessagePack decoding facilities to retrieve the full documents as needed:</p>

<p>``` java
// Query View
View view = cb.getView(&ldquo;designname&rdquo;, &ldquo;viewname&rdquo;);
ViewResponse response = cb.query(view, new Query().setIncludeDocs(true));</p>

<p>// Iterate and load full documents
for (ViewRow row : response) {
  System.out.println(msgpack.read((byte[]) row.getDocument()));
}
```</p>

<p>On the console, you&rsquo;ll see the full document content:</p>

<p><code>javascript
{"lastname":"Ingenthron","firstname":"Matt"}
{"lastname":"Nitschinger","firstname":"Michael"}
{"lastname":"Avseyev","firstname":"Sergey"}
</code></p>

<p>Of course, feel free to use all the well-known query mechanisms for Views.</p>

<h2>Benefits, anyone?</h2>

<p>Now one could argue that this is nice to play around with, but what do I actually gain from it? Arguably, there is more work included for the developer, and maybe for the Server side as well.</p>

<p>MessagePack makes bold claims that its faster and smaller than JSON, so lets try to verify this in our environment.</p>

<p>To verify the size argument, let&rsquo;s go ahead and create 1M docs with a &ldquo;reasonable&rdquo; size and store them both through JSON and MessagePack. Since the overhead for each document is static inside Couchbase Server, we can very easily see how much RAM is used to hold the documents and conclude on the size difference (which is what matters at the end).</p>

<p>``` java
int numdocs = 1000000;
HashMap&lt;String, Object> user = new HashMap&lt;String, Object>();
user.put(&ldquo;firstname&rdquo;, &ldquo;Michael&rdquo;);
user.put(&ldquo;lastname&rdquo;, &ldquo;Nitschinger&rdquo;);
user.put(&ldquo;age&rdquo;, 25);
user.put(&ldquo;loggedIn&rdquo;, false);
user.put(&ldquo;active&rdquo;, true);</p>

<p>for (int i = 0; i &lt; numdocs; i++) {
  cb.set(&ldquo;user:&rdquo; + i, msgpack.write(user)).get();
}
```</p>

<p>For 1M documents on my machine with Couchbase Server 2.0, the amount of RAM used is 166MB. Now, let&rsquo;s do the same with JSON. I&rsquo;m going to use <a href="https://code.google.com/p/google-gson/">Google GSON</a> to convert the HashMap:</p>

<p>``` java
int numdocs = 1000000;
HashMap&lt;String, Object> user = new HashMap&lt;String, Object>();
user.put(&ldquo;firstname&rdquo;, &ldquo;Michael&rdquo;);
user.put(&ldquo;lastname&rdquo;, &ldquo;Nitschinger&rdquo;);
user.put(&ldquo;age&rdquo;, 25);
user.put(&ldquo;loggedIn&rdquo;, false);
user.put(&ldquo;active&rdquo;, true);</p>

<p>for (int i = 0; i &lt; numdocs; i++) {
  cb.set(&ldquo;user:&rdquo; + i, gson.toJson(user)).get();
}
```</p>

<p>After inserting those 1M JSON records, Couchbase Server reported exactly 198MB of RAM used! So the difference is 32MB (1/5th of the total data size), or 32 byte per document. That pays off if you have lots of records in your cluster! After doubling the content of the HashMap and storing twice as many documents (2M) MessagePack is ahead of raw JSON by around 96MB. That&rsquo;s another 400K documents you could store (one document is around 230 bytes compared to 285 with raw JSON).</p>

<p>Of course, YMMV depending on the number and size of the documents. I&rsquo;m curious if you could do the same runs on your real workload and see by how much you could improve.</p>

<p>Now, before we talk about RAW encoding/decoding performance, we also need to look into the overhead involved on the server side. Storing and retreiving documents is not slower than any other document, because the server doesn&rsquo;t need to do anything special. The only overhead I can think of is that during index creation, more CPU will be consumed because you execute more JavaScript logic. I guess this CPU overhead increases with the document sizes, but I don&rsquo;t have any actual numbers to share here. Personally, I&rsquo;d use the <a href="">sizing</a> guidelines for Views and maybe add some more CPU just to be safe. It&rsquo;s important to note that at query time, you won&rsquo;t see a difference between JSON and MessagePack, because the index is already created.</p>

<p>Congratulations if you followed to this point! As a bonus, we&rsquo;ll look into the raw encoding/decoding performance of JSON and MessagePack on the JVM. Since there are lots of JSON libraries out there, we&rsquo;re going to use <a href="http://jackson.codehaus.org/">Jackson</a> and Google GSON. Benchmarking on the JVM is not a trivial task, so I&rsquo;ll do my best to keep it objective and we&rsquo;re going to use <a href="https://code.google.com/p/caliper/">Google Caliper</a> to handle things like JVM warmup. Make sure to add everything to your <code>pom.xml</code> like this:</p>

<p>``` xml
<dependency></p>

<pre><code>&lt;groupId&gt;org.msgpack&lt;/groupId&gt;
&lt;artifactId&gt;msgpack&lt;/artifactId&gt;
&lt;version&gt;0.6.7&lt;/version&gt;
</code></pre>

<p></dependency>
<dependency></p>

<pre><code>&lt;groupId&gt;com.google.code.gson&lt;/groupId&gt;
&lt;artifactId&gt;gson&lt;/artifactId&gt;
&lt;version&gt;2.2.4&lt;/version&gt;
</code></pre>

<p></dependency>
<dependency></p>

<pre><code>&lt;groupId&gt;com.google.caliper&lt;/groupId&gt;
&lt;artifactId&gt;caliper&lt;/artifactId&gt;
&lt;version&gt;1.0-beta-1&lt;/version&gt;
</code></pre>

<p></dependency>
<dependency></p>

<pre><code>&lt;groupId&gt;com.google.code.java-allocation-instrumenter&lt;/groupId&gt;
&lt;artifactId&gt;java-allocation-instrumenter&lt;/artifactId&gt;
&lt;version&gt;2.1&lt;/version&gt;
</code></pre>

<p></dependency>
<dependency></p>

<pre><code>&lt;groupId&gt;com.fasterxml.jackson.core&lt;/groupId&gt;
&lt;artifactId&gt;jackson-databind&lt;/artifactId&gt;
&lt;version&gt;2.2.2&lt;/version&gt;
</code></pre>

<p></dependency>
```</p>

<p>In this simple benchmark, we are only testing smaller and slightly larger <code>HashMap</code>s. I know that this test is not conclusive, but it should give you a starting point from where you can do your own research.</p>

<p>To write a Caliper benchmark, you need to extend the <code>Benchmark</code> class from the caliper package. its as simple as this:</p>

<p>``` java
public class EncodingBenchmark extends Benchmark {</p>

<p>  private final Gson gson = new Gson();
  private final MessagePack msgpack = new MessagePack();
  private final ObjectMapper mapper = new ObjectMapper();</p>

<p>  private HashMap&lt;String, Object> smallMap;
  private HashMap&lt;String, Object> largeMap;</p>

<p>  @Override
  protected void setUp() {</p>

<pre><code>smallMap = new HashMap&lt;String, Object&gt;();
smallMap.put("firstname", "Foo");
smallMap.put("lastname", "bar");
smallMap.put("active", false);

largeMap = new HashMap&lt;String, Object&gt;();
largeMap.put("firstname", "Foo");
largeMap.put("lastname", "bar");
largeMap.put("active", false);
largeMap.put("firstname1", "Foo");
largeMap.put("lastname1", "bar");
largeMap.put("active1", false);
largeMap.put("firstname2", "Foo");
largeMap.put("lastname2", "bar");
largeMap.put("active2", false);
largeMap.put("firstname3", "Foo");
largeMap.put("lastname3", "bar");
largeMap.put("active3", false);
</code></pre>

<p>  }</p>

<p>  public void timeMessagePackSmall(final int reps) throws Exception {</p>

<pre><code>for (int i = 0; i &lt; reps; i++) {
  msgpack.write(smallMap);
}
</code></pre>

<p>  }</p>

<p>  public void timeGoogleGsonSmall(int reps) throws Exception {</p>

<pre><code>for (int i = 0; i &lt; reps; i++) {
  gson.toJson(smallMap);
}
</code></pre>

<p>  }</p>

<p>  public void timeJacksonSmall(int reps) throws Exception {</p>

<pre><code>for (int i = 0; i &lt; reps; i++) {
  mapper.writeValueAsString(smallMap);
}
</code></pre>

<p>  }
  public void timeJsonSmartSmall(int reps) throws Exception {</p>

<pre><code>for (int i = 0; i &lt; reps; i++) {
  mapper.writeValueAsString(smallMap);
}
</code></pre>

<p>  }</p>

<p>  public void timeMessagePackLarge(final int reps) throws Exception {</p>

<pre><code>for (int i = 0; i &lt; reps; i++) {
  msgpack.write(largeMap);
}
</code></pre>

<p>  }</p>

<p>  public void timeGoogleGsonLarge(int reps) throws Exception {</p>

<pre><code>for (int i = 0; i &lt; reps; i++) {
  gson.toJson(largeMap);
}
</code></pre>

<p>  }</p>

<p>  public void timeJacksonLarge(int reps) throws Exception {</p>

<pre><code>for (int i = 0; i &lt; reps; i++) {
  mapper.writeValueAsString(largeMap);
}
</code></pre>

<p>  }
}
```</p>

<p>First, we create our converter instances (for MessagePack, GSON and Jackson) and the HashMaps. All the runs in this benchmark are executed by Caliper. We need to modify our <code>main</code> class to load the wrapper:</p>

<p>``` java
import business.MsgpackBenchmark;
import com.google.caliper.runner.CaliperMain;</p>

<p>public class Main {
  public static void main(String[] args) throws Exception {</p>

<pre><code>CaliperMain.main(EncodingBenchmark.class, args);
</code></pre>

<p>  }
}
```</p>

<p>Now if you run this in your IDE, you&rsquo;ll see some logging going on:</p>

<pre><code>Experiment selection: 
  Instruments:   [allocation, micro]
  User parameters:   {}
  Virtual machines:  [default]
  Selection type:    Full cartesian product

This selection yields 12 experiments.
Starting experiment 1 of 12: {instrument=allocation, method=GoogleGsonLarge, vm=default, parameters={}}
Complete!
Starting experiment 2 of 12: {instrument=allocation, method=GoogleGsonSmall, vm=default, parameters={}}
Complete!
Starting experiment 3 of 12: {instrument=allocation, method=JacksonLarge, vm=default, parameters={}}
Complete!
Starting experiment 4 of 12: {instrument=allocation, method=JacksonSmall, vm=default, parameters={}}
Complete!
...
Starting experiment 11 of 12: {instrument=micro, method=MessagePackLarge, vm=default, parameters={}}
Complete!
Starting experiment 12 of 12: {instrument=micro, method=MessagePackSmall, vm=default, parameters={}}
Complete!

Execution complete: 7.058m.
Collected 162 measurements from:
  2 instrument(s)
  1 virtual machine(s)
  6 benchmark(s)
Results have been uploaded. View them at: https://microbenchmarks.appspot.com/runs/f25820e0-08dd-43f8-833e-e44847400f19
</code></pre>

<p>Once finished, Caliper even uploaded your results to a webpage (so make sure to have internet connection)! Note that if you see &ldquo;GC errors&rdquo; during your runs, it may be good to retry and if they still persist, consider increasing your heap size a bit. I don&rsquo;t know for how long the data is held on the web page, but <a href="https://microbenchmarks.appspot.com/runs/f25820e0-08dd-43f8-833e-e44847400f19#r:scenario.benchmarkSpec.methodName">here</a> are my results.</p>

<p>At least in my benchmarks I found that libraries like Jackson outperform MessagePack by a large amount when encoding <code>HashMap</code>s. Maybe it&rsquo;s different with other data types and sizes though.</p>

<h2>Summary</h2>

<p>I hope this blog post was a fun introduction and showed what&rsquo;s possible with Couchbase Server 2.0 and its new View engine. I found that MessagePack really saves you a good amount of bytes on the wire (and on the server), but is much slower on the JVM when it comes to encoding data (here <code>HashMap</code>s).</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[A Couchbase Cluster in Minutes With Vagrant and Puppet]]></title>
    <link href="http://daschl.github.io/A-Couchbase-Cluster-in-Minutes-with-Vagrant-and-Puppet"/>
    <updated>2013-05-27T14:49:48+02:00</updated>
    <id>http://daschl.github.io/A-Couchbase-Cluster-in-Minutes-with-Vagrant-and-Puppet</id>
    <content type="html"><![CDATA[<h2>Motivation</h2>

<p>Since I work as part of the engineering team at Couchbase, I need to run my code against a variety of server deployments. We run a multitude of operating systems and software versions, and so do our customers. In order to fix bugs reliably and build new features, it is critical to get a cluster up and running that resembles these deployments as good as possible. I know that I can run all of these combinations on EC2, but the cost for this would be very high and most of the time its overkill.</p>

<p>What I need is to get such a cluster up and running in minutes and not spending too much time on configuring it. I heard about <a href="http://www.vagrantup.com/">Vagrant</a> and <a href="https://puppetlabs.com/">Puppet</a> in the past, but never got around to use them on my own box (though I always use <a href="https://www.virtualbox.org/">VirtualBox</a> on MacOS to create virtual machines by hand).</p>

<p>This morning I sat down to take a closer look on how these tools can help me to get more productive &ndash; and to my huge surprise I got a 4 node Couchbase Server cluster running in less than 30 minutes (with looking up all the configuration details). Since its so easy, I want to share it with you.</p>

<h2>Prerequisites</h2>

<p>Before we can provision our nodes, you need to make sure to have Vagrant and VirtualBox installed. If you use MacOS like me, just download the <code>.dmg</code> files for both and you&rsquo;re set. Now, create a directory somewhere to store the configuration files &ndash; I called mine &lsquo;vagrants&rsquo;.</p>

<p>In this directory, you need to create a <code>Vagrantfile</code>. Its like the Vagrants <code>makefile</code> and it will pick it up to learn how you want to have your nodes provisioned. Note that this doesn&rsquo;t configure the software on top of the OS (like installing Couchbase), this is handled by puppet in a separate step. Here is the full config:</p>

<p>``` ruby
Vagrant.configure(&ldquo;2&rdquo;) do |config|</p>

<pre><code># Number of nodes to provision
numNodes = 4

# IP Address Base for private network
ipAddrPrefix = "192.168.56.10"

# Define Number of RAM for each node
config.vm.provider "virtualbox" do |v|
    v.customize ["modifyvm", :id, "--memory", 1024]
end

# Provision the server itself with puppet
config.vm.provision :puppet

# Download the initial box from this url
config.vm.box_url = "http://files.vagrantup.com/precise64.box"

# Provision Config for each of the nodes
1.upto(numNodes) do |num|
    nodeName = ("node" + num.to_s).to_sym
    config.vm.define nodeName do |node|
        node.vm.box = "precise64"
        node.vm.network :private_network, ip: ipAddrPrefix + num.to_s
        node.vm.provider "virtualbox" do |v|
            v.name = "Couchbase Server Node " + num.to_s
        end
    end
end
</code></pre>

<p>end
```</p>

<p>This file is just ruby code that configures Vagrant. Let&rsquo;s go through each directive and see what it does for us.</p>

<p>``` ruby</p>

<h1>Number of nodes to provision</h1>

<p>numNodes = 4</p>

<h1>IP Address Base for private network</h1>

<p>ipAddrPrefix = &ldquo;192.168.56.10&rdquo;
```</p>

<p>You can change these values, I just created them to fit my environment here. Depending on the amount of <code>numNodes</code> set, VMs will be created. I added a loop down below depending on this setting, so I don&rsquo;t have to duplicate code a lot. The ip address prefix is used to easily determine the (static) IP address for the server. The numbers will be counted upwards incrementally, so you will end up with four servers accessible through <code>192.168.56.101</code> to <code>192.168.56.104</code>.</p>

<p>``` ruby</p>

<h1>Define Number of RAM for each node</h1>

<p>config.vm.provider &ldquo;virtualbox&rdquo; do |v|</p>

<pre><code>v.customize ["modifyvm", :id, "--memory", 1024]
</code></pre>

<p>end
```</p>

<p>This config block is needed to increase the memory size of the VM. By default its less than that (I believe around 512MB), and I want to have 1 gig of RAM for each. Of course, feel free to tune that value or remove it completely.</p>

<p>``` ruby</p>

<h1>Provision the server itself with puppet</h1>

<p>config.vm.provision :puppet
```</p>

<p>Because we&rsquo;ll be using puppet to provision the server software, we need to tell Vagrant to use it.</p>

<p>``` ruby</p>

<h1>Download the initial box from this url</h1>

<p>config.vm.box_url = &ldquo;<a href="http://files.vagrantup.com/precise64.box">http://files.vagrantup.com/precise64.box</a>&rdquo;
```</p>

<p>Vagrant reuses predefined images so you don&rsquo;t have to reinstall everything from scratch. Here we use a predefined Ubuntu 12.04 64bit box.</p>

<p>``` ruby</p>

<h1>Provision Config for each of the nodes</h1>

<p>1.upto(numNodes) do |num|</p>

<pre><code>nodeName = ("node" + num.to_s).to_sym
config.vm.define nodeName do |node|
    node.vm.box = "precise64"
    node.vm.network :private_network, ip: ipAddrPrefix + num.to_s
    node.vm.provider "virtualbox" do |v|
        v.name = "Couchbase Server Node " + num.to_s
    end
end
</code></pre>

<p>end
```</p>

<p>This code block configures each virtual machine. Given the number of nodes we want to create, for each of them it assigns an IP address and gives it a descriptive name inside Virtualbox. If you want to add server-dependent settings, the &ldquo;node&rdquo; block is the right place for it. Otherwise it will pick the cluster wide settings defined in the &ldquo;config&rdquo; block.</p>

<p>Now if we would run <code>vagrant up</code> from the command line in this directory, we&rsquo;d get four Ubuntu machines setup where we could SSH into, but nothing else would be installed. In order to make them do something, we want to install Couchbase Server. Puppet is a system automation software and very good at provisioning systems. Vagrant has amazing support for it, all we need to is create a <code>default.pp</code> file inside a <code>manifests</code> directory that looks like this:</p>

<p>``` plain
exec { &ldquo;couchbase-server-source&rdquo;:</p>

<pre><code>command =&gt; "/usr/bin/wget http://packages.couchbase.com/releases/2.0.1/couchbase-server-enterprise_x86_64_2.0.1.deb",
cwd =&gt; "/home/vagrant/",
creates =&gt; "/home/vagrant/couchbase-server-enterprise_x86_64_2.0.1.deb",
before =&gt; Package['couchbase-server']
</code></pre>

<p>}</p>

<p>exec { &ldquo;install-deps&rdquo;:</p>

<pre><code>command =&gt; "/usr/bin/apt-get install libssl0.9.8",
before =&gt; Package['couchbase-server']
</code></pre>

<p>}</p>

<p>package { &ldquo;couchbase-server&rdquo;:</p>

<pre><code>provider =&gt; dpkg,
ensure =&gt; installed,
source =&gt; "/home/vagrant/couchbase-server-enterprise_x86_64_2.0.1.deb"
</code></pre>

<p>}
```</p>

<p>Let&rsquo;s go over the internals once more.</p>

<p>``` plain
exec { &ldquo;couchbase-server-source&rdquo;:</p>

<pre><code>command =&gt; "/usr/bin/wget http://packages.couchbase.com/releases/2.0.1/couchbase-server-enterprise_x86_64_2.0.1.deb",
cwd =&gt; "/home/vagrant/",
creates =&gt; "/home/vagrant/couchbase-server-enterprise_x86_64_2.0.1.deb",
before =&gt; Package['couchbase-server']
</code></pre>

<p>}
```</p>

<p>In puppet, we define some tasks that we want to run. This task executes a shell command <code>wget</code> and stores the file inside the home directory of the user. We tell puppet to download the debian package of the server. Note that there is a <code>before</code> dependency to the package installation task, because we can&rsquo;t install it before the file wasn&rsquo;t downloaded.</p>

<p>``` plain
exec { &ldquo;install-deps&rdquo;:</p>

<pre><code>command =&gt; "/usr/bin/apt-get install libssl0.9.8",
before =&gt; Package['couchbase-server']
</code></pre>

<p>}
```</p>

<p>We also need to install <code>libssl0.9.8</code> on the server, this is the only dependency it has. We use the command line tool <code>apt-get</code> for this.</p>

<p>``` plain
package { &ldquo;couchbase-server&rdquo;:</p>

<pre><code>provider =&gt; dpkg,
ensure =&gt; installed,
source =&gt; "/home/vagrant/couchbase-server-enterprise_x86_64_2.0.1.deb"
</code></pre>

<p>}
```</p>

<p>Finally, we can install the debian package from couchbase-server, because the file is in place and all dependencies are satisfied.</p>

<p>Of course, this puppet file is very simple and I&rsquo;m you can do much more with it (and maybe even simplify it more) &ndash; but for my needs it is more than enough. If I want a different server version, I just need to change the puppet file and point it to the new debian package.</p>

<p>Now if we run <code>vagrant up</code> again, much more happens. Note that if you want to play with your puppet files, you can also use <code>vagrant provision</code> to apply the changes while the node is running.</p>

<p>If everything is okay, the output should look like this:</p>

<pre><code>Bringing machine 'node1' up with 'virtualbox' provider...
Bringing machine 'node2' up with 'virtualbox' provider...
Bringing machine 'node3' up with 'virtualbox' provider...
Bringing machine 'node4' up with 'virtualbox' provider...
[node1] Clearing any previously set forwarded ports...
[node1] Creating shared folders metadata...
[node1] Clearing any previously set network interfaces...
[node1] Preparing network interfaces based on configuration...
[node1] Forwarding ports...
[node1] -- 22 =&gt; 2222 (adapter 1)
[node1] Running any VM customizations...
[node1] Booting VM...
[node1] Waiting for VM to boot. This can take a few minutes.
[node1] VM booted and ready for use!
[node1] Configuring and enabling network interfaces...
[node1] Mounting shared folders...
[node1] -- /vagrant
[node1] -- /tmp/vagrant-puppet/manifests
[node1] Running provisioner: puppet...
Running Puppet with default.pp...
stdin: is not a tty
notice: /Stage[main]//Exec[install-deps]/returns: executed successfully
notice: Finished catalog run in 0.77 seconds
.... more for all the other nodes.
</code></pre>

<p>You can then point your browser to <code>192.168.56.10[1-4]</code> and work with your Couchbase cluster. If you are done with it, you can use the <code>vagrant halt</code> command to shut it down cleanly. Very handy is also <code>vagrant suspend</code>, which will save the state of the nodes instead of shutting them down completely.</p>

<p>If you want to interact with one of the nodes instead of the whole cluster, you can always specify the node identifier. For example, if you want to start only the first node you can do it with the <code>vagrant up node1</code> command.</p>

<p>To me, this is a very fast and clean way to provision server nodes. I just need to change a few lines in a file and get a new cluster without much hassle. Even more important, I can put those config files in version control and <a href="https://github.com/daschl/vagrants">share them</a> with other folks!</p>
]]></content>
  </entry>
  
</feed>
