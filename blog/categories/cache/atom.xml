<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">

  <title><![CDATA[Category: Cache | Nitschinger.at]]></title>
  <link href="http://nitschinger.at/blog/categories/cache/atom.xml" rel="self"/>
  <link href="http://nitschinger.at/"/>
  <updated>2013-12-19T10:22:50+01:00</updated>
  <id>http://nitschinger.at/</id>
  <author>
    <name><![CDATA[Michael Nitschinger]]></name>
    
  </author>
  <generator uri="http://octopress.org/">Octopress</generator>

  
  <entry>
    <title type="html"><![CDATA[Benchmarking Cache Transcoders in PHP]]></title>
    <link href="http://nitschinger.at/Benchmarking-Cache-Transcoders-in-PHP"/>
    <updated>2013-01-30T13:49:48+01:00</updated>
    <id>http://nitschinger.at/Benchmarking-Cache-Transcoders-in-PHP</id>
    <content type="html"><![CDATA[<h2>Motivation</h2>

<p>Storing PHP objects (or simpler data types like arrays) in caches always requires some kind of transformation. You need a way of encoding/decoding data so that it can be stored and loaded properly. In most languages, this process is known as object <a href="http://en.wikipedia.org/wiki/Serialization">serialization</a>. PHP provides a mechanism for this out of the box, but in this article we&rsquo;ll also look at <a href="http://pecl.php.net/package/igbinary">igbinary</a> as a drop-in replacement for the default serializer. We also compare the results to object transcoding based on <a href="http://json.org/">JSON</a>, which is not really an object serialization mechanism but commonly used as a data chache structure which has its own benefits and drawbacks.</p>

<p>As always, please take this benchmarks with a grain of salt. Don&rsquo;t take the absolute numbers as a reference, look at the differences and run the benchmarks in your environment to get accurate results that apply to your scenarios. If you spot any flaws in what is shown here, please point it out in the comments. This blog post is not some kind of &ldquo;advertising&rdquo; for a special mechanism and all different transcoders are discussed with their benefits and drawbacks.</p>

<p>If you want to compare your results to mine, I&rsquo;m using a MacBook Pro on Mac OS X 10.8.2 with the 2.3 GHz i7 and 16GB RAM. I&rsquo;m using PHP 5.4.11 (through <a href="https://github.com/josegonzalez/homebrew-php">homebrew-php</a>) instead of the shipped 5.3.</p>

<h2>The PHP Serializer</h2>

<p>Out of the box, PHP provides a serialization mechanism on top of the <a href="http://php.net/manual/de/function.serialize.php">serialize</a> and <a href="http://www.php.net/manual/de/function.unserialize.php">unserialize</a> methods. By applying this method on a variable, it gets encoded to a byte stream and neither the type nor the structure gets lost (you can&rsquo;t store <a href="http://www.php.net/manual/en/language.types.resource.php">resources</a>).</p>

<p>So, let&rsquo;s look at a simple and a more complex example on how the transformation looks like:</p>

<p>``` php
&lt;?php</p>

<p>class Person {</p>

<pre><code>private $name;

public function __construct($name) {
    $this-&gt;name = $name;
}

public function getName() {
    return $this-&gt;name;
}
</code></pre>

<p>}</p>

<p>$simple = array(&ldquo;key&rdquo; => &ldquo;value&rdquo;);
$complex = new Person(&ldquo;Michael&rdquo;);</p>

<p>?>
```</p>

<p>If we&rsquo;re calling <code>serialize()</code> on both variables, the output (as a string representation) looks like this:</p>

<p>``` php
&lt;?php
$simpleSerialized = serialize($simple);
$complexSerialized = serialize($complex);</p>

<p>// string(28) &ldquo;a:1:{s:3:"key&rdquo;;s:5:&ldquo;value&rdquo;;}&ldquo;
var_dump(serialize($simple));</p>

<p>// string(51) &ldquo;O:6:"Person&rdquo;:1:{s:12:&ldquo;\000Person\000name&rdquo;;s:7:&ldquo;Michael&rdquo;;}&ldquo;
var_dump(serialize($complex));
?>
```</p>

<p>While the resulting string is not designed for readability, you can clearly see that some metadata is added in order to make the unserialization possible. For example, the <code>key</code> string is serialized to <code>s:3:"key"</code> where the <code>s</code> means <code>string</code> and <code>3</code> is the string length. Also, <code>a</code> points to an <code>array</code> and <code>O</code> to an <code>object</code>.</p>

<p>We can now <code>unserialize()</code> the values and work with them as if they&rsquo;ve never been stored somewhere else:</p>

<p>``` php
&lt;?php
$simpleUnserialized = unserialize($simpleSerialized);
$complexUnserialized = unserialize($complexSerialized);</p>

<p>// array(1) {&lsquo;key&rsquo; => string(5) &ldquo;value&rdquo;}
var_dump($simpleUnserialized);</p>

<p>// string(7) &ldquo;Michael&rdquo;
var_dump($complexUnserialized->getName());
?>
```</p>

<p>In practice, two characteristics are important: size of the serialized value and performance. While from a developer perspective performance is fun to explore, the size of the serialized object is what matters most. Performance differences are only measurable when running it in a loop with lots of iterations, while in practice you may only work with a few objects at a time per request.</p>

<p>Let&rsquo;s use a common caching scenario: imagine we&rsquo;re caching entity responses from an ORM framework like <a href="http://www.doctrine-project.org/">Doctrine</a>. Here is a blog post class that will be filled with life:</p>

<p>``` php
&lt;?php
class BlogPost {</p>

<pre><code>private $title;
private $teaser;
private $author;
private $body;

public function __construct($title, $teaser, $author, $body) {
    $this-&gt;title = $title;
    $this-&gt;teaser = $teaser;
    $this-&gt;author = $author;
    $this-&gt;body = $body;
}

public function getTitle() { return $this-&gt;title; }
public function getTeaser() { return $this-&gt;teaser; }
public function getAuthor() { return $this-&gt;author; }
public function getBody() { return $this-&gt;body; }
</code></pre>

<p>}
?>
```</p>

<p>Please take this with a grain of salt, because since JSON transcoding is not able to store a 1:1 representation like <code>serialize</code>, we need to work around that a bit. More details and discussion will be provided in the JSON section.</p>

<p>Assume that a blog post with content has around 10k characters and about 10kb in size, lets create a crafted blog post:</p>

<p>``` php
&lt;?php
$randomString = function ($length) {</p>

<pre><code>$chars = "abcdefghijklmnopqrstuvwxyzABCDEFGHIJKLMNOPQRSTUVWXYZ0123456789 .";    
$str = "";
for( $i = 0; $i &lt; $length; $i++ ) {
    $str .= $chars[rand(0, strlen($chars)-1)];
}
return $str;
</code></pre>

<p>};</p>

<p>$title = &ldquo;How to measure caching transcoders&rdquo;;
$teaser = &ldquo;This is a much longer introduction on how to measure caching transcoders. Feel free to post your own findings.&rdquo;;
$author = &ldquo;daschl&rdquo;;
$body = $randomString(10000);</p>

<p>$post = new BlogPost($title, $teaser, $author, $body);
?>
```</p>

<p>Now run <code>serialize</code> and <code>unserialize</code> in loops to measure performance as well as determine the resulting size of the object:</p>

<p>``` php
&lt;?php
$iterations = 10000;
$start = microtime(true);
for($i=0;$i&lt;$iterations;$i++) {</p>

<pre><code>$serialized = serialize($post);
</code></pre>

<p>}
$end = microtime(true);</p>

<p>echo &ldquo;Size: &rdquo; . strlen($serialized) . &ldquo;\n&rdquo;;
echo ($end &ndash; $start) * 1000 . &ldquo;Milliseconds\n&rdquo;;
?>
```</p>

<p>On my machine, to serialize 10000 objects it took about 33 milliseconds. The length of the resulting object (its string representation) is 10297 characters. This is kind of expected because the bulk of the object is the long article body. Before start comparing, we can already make one observation: its pretty fast. Now, let&rsquo;s move on to igbinary serialization and see how these results compare.</p>

<h2>Serializing with igbinary</h2>

<p>The <a href="http://pecl.php.net/package/igbinary">igbinary</a> extension was developed as a drop-in replacement for the default PHP serializer. Instead of storing the serialized object as a text, it is stored as binary data. You can install it either through PECL or compile it from source, either way before running the tests make sure you have the <code>igbinary</code> extension enabled:</p>

<pre><code>michael@daschlbook ~ $ php -m | grep igbinary
igbinary
</code></pre>

<p>Instead of using <code>serialize</code> or <code>unserialize</code>, igbinary provides us with appropriate <code>igbinary_serialize</code> and <code>igbinary_unserialize</code> functions. Now we can apply the same microbenchmark and see the results:</p>

<p>``` php
&lt;?php
$iterations = 10000;
$start = microtime(true);
for($i=0;$i&lt;$iterations;$i++) {</p>

<pre><code>$serialized = igbinary_serialize($post);
</code></pre>

<p>}
$end = microtime(true);</p>

<p>echo &ldquo;Size: &rdquo; . strlen($serialized) . &ldquo;\n&rdquo;;
echo ($end &ndash; $start) * 1000 . &ldquo;Milliseconds\n&rdquo;;
?>
```</p>

<p>With default settings, to serialize 10000 objects with igbinary it took 678 milliseconds. The length of the resulting object is 10244 characters. If you compare it with the default serialization mechanism, that is 20 times slower and the resulting object isn&rsquo;t much smaller either. Bummer &ndash; or not? Let&rsquo;s look at why this is happening.</p>

<p>Let&rsquo;s look at a different workload. Let&rsquo;s create a data structure which consist of 30 smaller blog posts and measure the statistics for both again (only doing 1000 iterations instead of 10000):</p>

<p>``` php
&lt;?php
$posts = array();
for($i=0;$i&lt;30;$i++) {</p>

<pre><code>$posts[] = new BlogPost($title, $teaser, $author, $randomString(50));
</code></pre>

<p>}
?>
```</p>

<p>The results are more interesting: on my machine igbinary takes about 95 milliseconds while serialize needs only 41 milliseconds. Now it&rsquo;s just 2 times slower. But here comes the important part: the resulting size of igbinary is 2385 characters, while serialize is 10467 characters! That&rsquo;s about 5 times smaller. Note that this gap increases the larger your PHP object gets (not in terms of long character strings but speaking of complexity like methods).</p>

<p>Note that the igbinary docs say you should set <code>igbinary.compact_strings</code> to <code>Off</code> to increase performance, but there was no real measurable difference in my testings.</p>

<p>There is one more thing we haven&rsquo;t compared: deserializing of previously serialized objects. We can take the same code from above, use the serialized part as input and measure the timings once again (not that we don&rsquo;t need to measure the size of the resulting object because we&rsquo;re creating a &ldquo;live&rdquo; object again):</p>

<p>``` php
&lt;?php
$posts = array();
for($i=0;$i&lt;30;$i++) {</p>

<pre><code>$posts[] = new BlogPost($title, $teaser, $author, $randomString(50));
</code></pre>

<p>}</p>

<p>$serializedIgbinary = igbinary_serialize($posts);
$serializedClassic = serialize($posts);</p>

<p>$iterations = 1000;
$start = microtime(true);
for($i=0;$i&lt;$iterations;$i++) {</p>

<pre><code>$unserialized = igbinary_unserialize($serializedIgbinary);
</code></pre>

<p>}
$end = microtime(true);</p>

<p>echo ($end &ndash; $start) * 1000 . &ldquo;Milliseconds\n&rdquo;;</p>

<p>$start = microtime(true);
for($i=0;$i&lt;$iterations;$i++) {</p>

<pre><code>$unserialized = unserialize($serializedClassic);
</code></pre>

<p>}
$end = microtime(true);</p>

<p>echo ($end &ndash; $start) * 1000 . &ldquo;Milliseconds\n&rdquo;;
?>
```</p>

<p>This is giving us very interesting results: igbinary takes 65 milliseconds while classic unserialize needs 82 milliseconds! So igbinary is faster here. This is pretty good news, because in practice you will need to unserialize (speak &ldquo;fetch from cache&rdquo;) much more often than to serialize (speak &ldquo;store in cache&rdquo;). That&rsquo;s the whole point of a cache.</p>

<p>Before we move on to JSON, I think it&rsquo;s fair to say that igbinary wins this comparison. Most of the time you want to store complex PHP objects and fetch them out fast and quickly. Of course it has the overhead of installing it as an extension, but since it&rsquo;s a drop-in replacement you can change your mind later (but take this with a grain of salt because you can only unserialize what was serialized with igbinary and vice versa &ndash; so you&rsquo;d need to fetch and restore them).</p>

<p>Finally, when you are storing very long strings in objects, both have pretty much the same overhead (because you can&rsquo;t &ldquo;compact&rdquo; this long string very well). One workaround may be to compress and decompress the string as needed, using a mixture of gzip and base64 encoding. When serializing PHP objects, you can use the <a href="http://www.php.net/manual/en/language.oop5.magic.php#object.sleep">__sleep</a> and <a href="http://www.php.net/manual/en/language.oop5.magic.php#object.wakeup">__wakeup</a> methods to perform these kind of transformations.</p>

<p>Adding these two methods to our <code>BlogPost</code> class results in a 20% saving when using the 10k random string again:</p>

<p>``` php
&lt;?php
public function __sleep() {</p>

<pre><code>$this-&gt;body = gzdeflate($this-&gt;body, 9);
return array('title', 'teaser', 'author', 'body');
</code></pre>

<p>}</p>

<p>public function __wakeup() {</p>

<pre><code>$this-&gt;body = gzinflate($this-&gt;body);
</code></pre>

<p>}
?>
```</p>

<p>Note that compressing takes time too, so measure if it makes sense in your case and the space savings are good enough. You also need the <code>zblib</code> extension to make this work properly.</p>

<h2>Transcoding on top of JSON</h2>

<p>First of all, JSON has not the same characteristics as serialization. This is just because JSON only supports a subset of the available data types that PHP supports and therefore encoding/decoding takes some extra steps on the application side. So why are we comparing it here? Well, JSON is used very often for storing data in caches. Not only is it human readable, it can also be used in combination with other languages and applications. Using JSON allows you to store cache information from a Java backend and use it in your PHP application. That doesn&rsquo;t work with traditional serialization approaches.</p>

<p>If you need a primer on JSON and PHP, <a href="http://nitschinger.at/Handling-JSON-like-a-boss-in-PHP">read</a> my other article first. PHP allows you to transcode all objects (except resources) through the <a href="http://www.php.net/manual/en/function.json-encode.php">json_encode</a> and <a href="http://www.php.net/manual/en/function.json-decode.php">json_decode</a> functions. Private and protected variables are not converted, so we either need to make them public or provide a custom method that exports a storable object structure. While we&rsquo;re at it, we can provide a static factory method that initializes our BlogPost from the returned JSON string:</p>

<p>``` php
&lt;?php
public function toJson() {</p>

<pre><code>return array(
    'title' =&gt; $this-&gt;title,
    'teaser' =&gt; $this-&gt;teaser,
    'author' =&gt; $this-&gt;author,
    'body' =&gt; $this-&gt;body
);
</code></pre>

<p>}</p>

<p>public static function fromJson($json) {</p>

<pre><code>$d = json_decode($json, true);
return new BlogPost($d['title'], $d['teaser'], $d['author'], $d['body']);
</code></pre>

<p>}
?>
```</p>

<p>Note that the <code>toJson()</code> method returns a simple representation of the object, which is much less complicated than a full serialization approach. Let&rsquo;s run our benchmark again:</p>

<p>``` php
&lt;?php
$post = new BlogPost($title, $teaser, $author, $randomString(10000));
$post = $post->toJson();</p>

<p>$iterations = 10000;
$start = microtime(true);
for($i=0;$i&lt;$iterations;$i++) {</p>

<pre><code>$encoded = json_encode($post);
</code></pre>

<p>}
echo &ldquo;Size: &rdquo; . strlen($serialized) . &ldquo;\n&rdquo;;
$end = microtime(true);</p>

<p>echo ($end &ndash; $start) * 1000 . &ldquo;Milliseconds\n&rdquo;;
?>
```</p>

<p>On my machine it takes 1.7 seconds (!) to complete the encoding. The resulting object size is 10196 bytes which is comparable to our earlier measurements (again, the large value dominates here). Testing it against complex objects is not interesting because we can&rsquo;t restore them anyway without further modifications. Running <code>json_decode</code> on the encoded object also takes around 1.5 seconds, so there is no major difference here.</p>

<p>Personally, I&rsquo;d expected to have JSON transcoding to perform better, but again normally you don&rsquo;t run 10k iterations in a row. When you break it down to 10 encodings they take about 1 millisecond which is okay for most scenarios (given we encode a really large objects with a few kb here). Smaller objects like user sessions will encode much faster.</p>

<p>Edit: a friendly reader on <a href="http://www.reddit.com/r/PHP/comments/17kcy3/benchmarking_cache_transcoders_in_php/">reddit</a> pointed out that you can (and should) use the <a href="http://www.php.net/manual/en/class.jsonserializable.php">JsonSerializable interface</a> instead of rolling your own method name like <code>toJson()</code>. Thanks!</p>

<p>Edit2: another reader pointed out that naming a method <code>toJson()</code> which does not return JSON but an array is misleading. I agree, so if you adapt this approach in your environment choose a better name like <code>prepareForJson()</code>, <code>toArray()</code> or use the <code>JsonSerializable</code> Interface as shown above.</p>

<h2>Conclusion</h2>

<p>After running these microbenchmarks, my conclusion is that when you need object serialization, go with igbinary. It provides good enough serialization performance and huge wins on object sizes. Decoding performance is also much better than out-ouf-the-box serialization. If you need interoperability with other applications or if you don&rsquo;t want to limit yourself to serialized PHP blobs, go with JSON. JSON requires much more hand wiring but you&rsquo;ll gain a lot of flexibility.</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Caching Doctrine Entities With Couchbase]]></title>
    <link href="http://nitschinger.at/Caching-Doctrine-Entities-with-Couchbase"/>
    <updated>2013-01-08T13:49:48+01:00</updated>
    <id>http://nitschinger.at/Caching-Doctrine-Entities-with-Couchbase</id>
    <content type="html"><![CDATA[<h2>Motivation</h2>

<p>As part of our ongoing efforts to make Couchbase more integrated with frameworks and libraries, we added caching support for the <a href="http://www.doctrine-project.org/">Doctrine ORM</a>. Recently, the pull request has been merged into the master branch and is scheduled to be published along with the <a href="http://doctrine-project.org/jira/browse/DCOM/fixforversion/10327">2.4</a> release.</p>

<p>Caching can either be used standalone (through the API provided by <a href="http://www.doctrine-project.org/projects/common.html">doctrine/common</a>) or integrated with the ORM functionality. We&rsquo;ll look at both variants through simple examples, a good documentation can also be found <a href="http://docs.doctrine-project.org/en/latest/reference/caching.html">here</a>. Note that at the time of writing, the CouchbaseCache is not mentioned as a caching driver because the documentation still needs to be updated.</p>

<p>Since 2.4 has not been released yet, we need to work against the <code>2.4.x-dev</code> branch. We&rsquo;ll be using <a href="http://getcomposer.org/">Composer</a> to fetch our dependencies, so just need change the version number if you want to pin it down to 2.4 later.</p>

<h2>Simple Caching</h2>

<p>Our first example shows how the caching API can be used directly. If you are familiar with the Couchbase API, you may think that it&rsquo;s more or less just a different API with the same (and maybe less) semantics, but the point is that it uses the Doctrine Cache API interface and as a result you can switch between different caching implementations very easily.</p>

<p>Create a directory called <code>couchbase-doctrine-simple</code> with the following <code>composer.json</code> inside:</p>

<p>``` javascript
{</p>

<pre><code>"require": {
    "doctrine/common": "2.4.x-dev",
    "ext-couchbase": "1.1.x"
}
</code></pre>

<p>}
```</p>

<p>This installs the <a href="https://packagist.org/packages/doctrine/common">doctrine/common</a> package and also makes sure that we have the <code>couchbase.so</code> extension in place. If you haven&rsquo;t installed the Couchbase PHP extension already, head over to the <a href="http://www.couchbase.com/develop/php/current">official website</a> and install it based on the tutorial and the docs.</p>

<p>Create a <code>index.php</code> with the following content (we&rsquo;ll break up the code afterwards):</p>

<p>``` php
&lt;?php
// 0: Composer Autoloader
require &lsquo;vendor/autoload.php&rsquo;;</p>

<p>// 1: Open the Couchbase Connection
$couchbase = new Couchbase(&ldquo;127.0.0.1&rdquo;, &ldquo;&rdquo;, &ldquo;&rdquo;, &ldquo;default&rdquo;);</p>

<p>// 2: Instantiate the Driver &amp; Inject the Connection
$cacheDriver = new \Doctrine\Common\Cache\CouchbaseCache();
$cacheDriver->setCouchbase($couchbase);</p>

<p>// 3: Execute your commands!
$key = &ldquo;my-cache-item&rdquo;;</p>

<p>if(!$cacheDriver->contains($key)) {</p>

<pre><code>$cacheDriver-&gt;save($key, "my_data");
</code></pre>

<p>} else {</p>

<pre><code>echo $cacheDriver-&gt;fetch($key);
</code></pre>

<p>}
?>
```</p>

<p>First, we need to bootstrap the composer autoloader so we don&rsquo;t have to write all <code>require</code> statements on our own. The next thing we need to do is actually connect to the Couchbase cluster:</p>

<p><code>php
// 1: Open the Couchbase Connection
$couchbase = new Couchbase("127.0.0.1", "", "", "default");
</code></p>

<p>Here, we&rsquo;re connecting to a node in the cluster which points at <code>localhost</code>, but you can pass in an array of nodes as well. We connect to the <code>default</code> bucket, which has no password. Now that we have our connection established, we can instantiate the cache driver and inject our Couchbase client:</p>

<p><code>php
// 2: Instantiate the Driver &amp; Inject the Connection
$cacheDriver = new \Doctrine\Common\Cache\CouchbaseCache();
$cacheDriver-&gt;setCouchbase($couchbase);
</code></p>

<p>From here on, the API is the same for all cache drivers. The following code checks if the cache contains a key. If it is present, it prints out the document but if it isn&rsquo;t it creates a new one. This is a very simple example but shows how you can start to use Couchbase caching in your own projects with just a few lines of bootstrapping!</p>

<p>Aside from these three methods, there is also a <code>delete</code> method available. Finally, you can pass an optional third param on <code>save</code> with a <code>$lifeTime</code> so that the cache item vanishes automatically.</p>

<p>Since Couchbase Server doesn&rsquo;t care what you store, you can also save and fetch any kind of datatype (aside from resources):</p>

<p><code>php
$cacheDriver-&gt;save($key, array('foo' =&gt; 'bar'));
var_dump($cacheDriver-&gt;fetch($key));
</code></p>

<p>Note that when you use the driver at this level, try to store JSON strings when you can (use <code>json_encode</code>/<code>json_decode</code> on your datastructures) This way you can take advantage of the brand new view engine inside Couchbase Server 2.0. You can always just store serialized objects as well (like we need to do with ORM integration) since for Couchbase Server it&rsquo;s just a byte stream.</p>

<p>We can now build on this foundation and see how this works with ORM integration.</p>

<h2>ORM Integration</h2>

<p>Create a new directory called <code>couchbase-doctrine-orm</code> with the following <code>composer.json</code>:</p>

<p>``` javascript
{</p>

<pre><code>"require": {
    "doctrine/orm": "2.4.x-dev",
    "doctrine/dbal": "2.4.x-dev",
    "doctrine/common": "2.4.x-dev",
    "ext-couchbase": "1.1.x"
},
"autoload": {
    "psr-0": {
        "Entities": "src/"
    }
}
</code></pre>

<p>}
```</p>

<p>This time our <code>composer.json</code> file is a little bit longer, because we need to define all of our dependencies by hand (since we don&rsquo;t want to work against the stable release). Since we need to define Doctrine Entities we pass the composer autoloader the custom directory (<code>src/</code>).</p>

<p>The next thing we need is our actual entity that we want to manage through Doctrine. Go ahead and create a <code>Person.php</code> file inside the <code>src/Entities</code> directory with the following content:</p>

<p>``` php
&lt;?php</p>

<p>namespace Entities;</p>

<p>/<em>* @Entity </em>/
class Person {</p>

<pre><code>/**
 * @Id @Column(type="integer") @GeneratedValue(strategy="AUTO")
 */
private $id;

/** @Column(type="string") */
private $firstname;

/** @Column(type="string") */
private $lastname;

public function setFirstname($firstname) {
    $this-&gt;firstname = $firstname;
}

public function getFirstname() {
    return $this-&gt;firstname;
}

public function setLastname($lastname) {
    $this-&gt;lastname = $lastname;
}

public function getLastname() {
    return $this-&gt;lastname;
}
</code></pre>

<p>}</p>

<p>?>
```</p>

<p>This is a very simple Doctrine Entity that has some properties and also a autogenerated <code>ID</code> field. I&rsquo;m going to use <a href="http://www.sqlite.org/">SQLite</a> in the following example, but feel free to use MySQL or any other relational database that you have available.</p>

<p>To wire everything together, we&rsquo;re going to create a <code>index.php</code> file in the root directory of the project. Again, here is the full content and we&rsquo;re going to break it apart afterwards:</p>

<p>``` php
&lt;?php
// Composer autoloader.
$loader = require &lsquo;vendor/autoload.php&rsquo;;</p>

<p>/<em>*
 * Initialize Couchbase &amp; the Cache.
 </em>/
$couchbase = new Couchbase(&ldquo;127.0.0.1&rdquo;, &ldquo;&rdquo;, &ldquo;&rdquo;, &ldquo;default&rdquo;);
$cacheDriver = new \Doctrine\Common\Cache\CouchbaseCache();
$cacheDriver->setCouchbase($couchbase);</p>

<p>/<em>*
 * Initialize the Entity Manager.
 </em>/
$paths = array(<strong>DIR</strong> . &lsquo;/src/Entities/&rsquo;);
$isDevMode = true;
$dbParams = array(</p>

<pre><code>'driver' =&gt; 'pdo_sqlite',
'user' =&gt; 'root',
'password' =&gt; '',
'path' =&gt; __DIR__ . '/cbexample.sqlite'
</code></pre>

<p>);</p>

<p>$config = \Doctrine\ORM\Tools\Setup::createAnnotationMetadataConfiguration($paths, $isDevMode, null, $cacheDriver);
$em = \Doctrine\ORM\EntityManager::create($dbParams, $config);</p>

<p>/<em>*
 * Work with our Entities.
 </em>/
$person = new \Entities\Person();
$person->setFirstname(&ldquo;Michael&rdquo;);
$person->setLastname(&ldquo;Nitschinger&rdquo;);</p>

<p>$em->persist($person);
$em->flush();</p>

<p>// Query with Result Cache
$query = $em->createQuery(&lsquo;select p from Entities\Person p&rsquo;);
$query->useResultCache(true);
$results = $query->getResult();</p>

<p>?>
```</p>

<p>Since this may be a lot to grasp, let&rsquo;s break it into smaller sized chunks.</p>

<p><code>php
$couchbase = new Couchbase("127.0.0.1", "", "", "default");
$cacheDriver = new \Doctrine\Common\Cache\CouchbaseCache();
$cacheDriver-&gt;setCouchbase($couchbase);
</code></p>

<p>After our bootstrapping the autoloader, we&rsquo;re initializing the cache driver. You already know what this means because we&rsquo;ve used the same code in the simple example before.</p>

<p>``` php
$paths = array(<strong>DIR</strong> . &lsquo;/src/Entities/&rsquo;);
$isDevMode = true;
$dbParams = array(</p>

<pre><code>'driver' =&gt; 'pdo_sqlite',
'user' =&gt; 'root',
'password' =&gt; '',
'path' =&gt; __DIR__ . '/cbexample.sqlite'
</code></pre>

<p>);</p>

<p>$config = \Doctrine\ORM\Tools\Setup::createAnnotationMetadataConfiguration($paths, $isDevMode, null, $cacheDriver);
$em = \Doctrine\ORM\EntityManager::create($dbParams, $config);
```</p>

<p>The <code>\Doctrine\ORM\EntityManager</code> is one of the major building blocks inside Doctrine and needs to be initialized accordingly. Therefore, we need to provide it a valid configuration. Here we&rsquo;re going to use annotations (as seen on the Doctrine Entity, but you can also do it through XML or YAML). We also need to provide our database connection and the path to the entities. The important part here is that we pass the <code>$cacheDriver</code> to the factory method. This automatically initializes our <code>CouchbaseCache</code> to be used for all kinds of caching (Query, Metadata and Result caching).</p>

<p>Now we can go ahead and create a record:</p>

<p>``` php
$person = new \Entities\Person();
$person->setFirstname(&ldquo;Michael&rdquo;);
$person->setLastname(&ldquo;Nitschinger&rdquo;);</p>

<p>$em->persist($person);
$em->flush();
```</p>

<p>Afterwards, we can fetch it back through a query:</p>

<p><code>php
$query = $em-&gt;createQuery('select p from Entities\Person p');
$query-&gt;useResultCache(true);
$results = $query-&gt;getResult();
</code></p>

<p>Note that we explicitely tell it to cache this query result for us (by default, result caching won&rsquo;t be used). If open the browser and point it to your Couchbase Server 2.0 management UI, you can see that Doctrine did create lots of documents behind the scenes. These are subsequently used to boost your application performance.</p>

<h2>Summary</h2>

<p>As you can see, using Couchbase as a Cache for Doctrine is not hard. You just need to initialize it and pass it into the configuration. From this point on, everything happens behind the scenes. And don&rsquo;t forget that you not only get exceptional performance, but also persistence, scalability and all the cool stuff that Couchbase Server provides out of the box.</p>

<p>If you have any questions or input, please let me know in the comments! Finally, thanks to <a href="https://twitter.com/Ocramius">Marco Pivetta</a> for helping me debug an <a href="https://github.com/doctrine/common/pull/240">issue</a> with ORM integration!</p>
]]></content>
  </entry>
  
</feed>
