<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>hwloc on daschl writes. sometimes.</title>
    <link>https://nitschinger.at/tags/hwloc/</link>
    <description>Recent content in hwloc on daschl writes. sometimes.</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language>
    <lastBuildDate>Thu, 11 Feb 2016 00:00:00 +0000</lastBuildDate><atom:link href="https://nitschinger.at/tags/hwloc/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>Binding Threads And Processes to CPUs in Rust</title>
      <link>https://nitschinger.at/Binding-Threads-And-Processes-to-CPUs-in-Rust/</link>
      <pubDate>Thu, 11 Feb 2016 00:00:00 +0000</pubDate>
      
      <guid>https://nitschinger.at/Binding-Threads-And-Processes-to-CPUs-in-Rust/</guid>
      <description>In the previous post I&amp;rsquo;ve introduced the hwloc-rs library, which allows you to discover and manage hardware topologies. Discovering the capabilities of a machine is insightful, but it gets more interesting if you can perform certain actions based on those insights.
Binding threads or processes to distinct CPU cores is very important in high performance applications to isolate workloads, keep inter-core messaging latency to a minimum and also to prevent the operating system from relocating your threads between cores as it sees fit.</description>
    </item>
    
    <item>
      <title>Discovering Hardware Topology in Rust</title>
      <link>https://nitschinger.at/Discovering-Hardware-Topology-in-Rust/</link>
      <pubDate>Fri, 08 Jan 2016 00:00:00 +0000</pubDate>
      
      <guid>https://nitschinger.at/Discovering-Hardware-Topology-in-Rust/</guid>
      <description>Todays programming languages and operation systems provide a bunch of abstraction layers over our hardware. Most of the time this is great, since we can write code quickly and make it run on lots of different machines. The opportunity cost with abstraction is (most of the time) performance and a lack of understanding.
To get the best performance out of hour hardware, it is important to understand it. Concepts like cache locality matter a lot, especially in modern NUMA architectures.</description>
    </item>
    
  </channel>
</rss>
